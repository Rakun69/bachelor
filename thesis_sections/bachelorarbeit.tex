\documentclass[english,bibtotoc,liststotoc,oneside,BCOR=5mm,DIV=12]{scrbook}
\recalctypearea

\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
\usepackage{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{pgfplots}
\usepackage{booktabs}
\usepackage{siunitx}
\pgfplotsset{compat=1.18}
\usepackage{listings, color}
\usepackage{subcaption}
\usepackage[automark]{scrlayer-scrpage}
\setlength{\marginparwidth}{2cm}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit,backgrounds,shadows,decorations.pathmorphing,decorations.pathreplacing}
\usetikzlibrary{calc,intersections,through,backgrounds,matrix}
\usetikzlibrary{arrows.meta, calc, positioning, shapes.geometric}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{array}
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\usepackage[table]{xcolor}
\usepackage[most]{tcolorbox}
\tcbuselibrary{listings,skins}
% Neutral panel with teal accent for algorithms/notes
\newtcolorbox{algwithnotes}[1][]{enhanced,breakable,sharp corners,boxrule=0.6pt,
  colback=blue!3!white,colframe=black!20,borderline west={2pt}{0pt}{teal!70!black},
  title={#1},fonttitle=\bfseries}

% Listings style for nicer code blocks
\lstdefinestyle{codeblock}{%
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  framerule=0.5pt,
  backgroundcolor=\color{blue!5!white},
  rulecolor=\color{teal!70!black},
  numbers=left,
  numberstyle=\tiny,
  numbersep=16pt,
  xleftmargin=2.6em,
  framexleftmargin=2.0em
}
\lstset{style=codeblock}

% Theorem-like environments
\newtheorem{definition}{Definition}

\usepackage{booktabs}
\usepackage{csquotes}
\usepackage[backend=biber, style=ieee]{biblatex}
\addbibresource{bib/references.bib}

% Only number and list up to sections (no subsection/subsubsection numbering in ToC or headings)
\setcounter{secnumdepth}{1}
\setcounter{tocdepth}{1}

\clearpairofpagestyles
\chead[Verifiable Data Transformations in IoT Environments – Ramón Felipe Kühne]{Verifiable Data Transformations in IoT Environments – Ramón Felipe Kühne}
% Unified footer for all page styles (plain and scrheadings)
\cfoot[TU Berlin, 2025 \quad | \quad \thepage]{TU Berlin, 2025 \quad | \quad \thepage}
\KOMAoptions{headsepline=.4pt}
\renewcommand*{\chapterpagestyle}{scrheadings}
\pagestyle{scrheadings}

\graphicspath{{./img/}{../data/visualizations/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\frontmatter
\input{misc/titlepage}
    \thispagestyle{empty}
    \cleardoublepage
    
\input{misc/self-assertion}
    \thispagestyle{empty}
    \cleardoublepage

% Switch to arabic numbering for all following pages
\mainmatter
\pagenumbering{arabic}
\setcounter{page}{1}

\section*{Declaration of Authorship}
I hereby declare that I have written this thesis independently and have not used any sources or aids other than those stated. All passages taken directly or indirectly from the published or unpublished work of others have been identified as such. This thesis has not been submitted in substantially the same form to any other examination board and has not been published.

\clearpage

\section*{Abstract}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\clearpage
\cleardoublepage
\listoffigures
\clearpage
\listoftables
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{sec:intro}

\section{Motivation}
\label{sec:motivation}
IoT deployments such as smart home sensors, industrial monitors, and environmental sensing networks generate continuous high resolution time series data. To reduce communication and storage demands on resource constrained edge devices, this data is often aggregated in batches, for example via summation or averaging. Conventional aggregation lacks formal guarantees regarding data integrity and privacy \cite{SmartMeterPrivacySurvey2023, AStudyOnPrivacyPreserving2021}. Research has shown that even coarse patterns like hourly energy usage can expose private habits \cite{muellerGewinnungVerhaltensprofilenAm2010}. Aggregation pipelines that rely on unverified local computation are susceptible to tampering or omission, which undermines trust in reported values \cite{bohliPrivacyModelSmart2010aa}. This combination of emerging privacy threats and trust issues highlights the need for cryptographic verification mechanisms in IoT aggregation systems.

Global data production has exploded over the past decade. In 2010 approximately 2 zettabytes of data existed. By 2023 that number reached about 120 zettabytes. In 2024 it rose to approximately 147 zettabytes. Projections expect global data volume to grow further to 181 zettabytes by 2025 \cite{IDCExpect175, HowMuchData}. This dramatic increase magnifies the potential impact of large scale data breaches. In the healthcare sector alone the number of breaches reported to U.S. authorities reached 725 in 2023, exposing over 133 million records \cite{alderDecember2023Healthcare2024}.

The proliferation of IoT devices further accelerates data generation and increases privacy risk. Smart thermostats, smart meters, wearable health trackers, voice assistants, and environmental sensors continuously collect sensor data, often without users’ full awareness. These devices shape daily life and generate intimate behavioral insights.

Because massive volumes of data are generated every moment and breaches are escalating, ensuring the integrity and confidentiality of aggregated data has become critically important. This motivates the development of cryptographic methods that can verify aggregated IoT data without compromising user privacy.

\section{Problem Statement}
\label{sec:problemstatement}
The central problem of this thesis has two main aspects. First, existing aggregation methods do not provide formal integrity guarantees. In practice, users cannot confirm that published aggregates include all raw sensor readings nor detect whether any data were omitted or modified during processing. Second, although zkSNARKs allow confidential proofs of correctness, classical non recursive approaches become increasingly inefficient when used repeatedly for continuous streaming data. The core inefficiency stems from computational complexity, especially during witness generation, which can easily become a bottleneck on IoT hardware with limited resources \cite{ElHajj2024BenchmarkStudy}. In addition, many traditional zkSNARK protocols depend on a trusted setup and do not allow parallel processing, which limits their scalability in IoT use cases.

Recursive zkSNARKs present a promising alternative. They support proof chaining across batches, so that verification cost is amortized rather than repeated. Recent systems such as GENES demonstrate substantial improvements in proving time and verification latency through recursive proof composition. However, these improvements sometimes come with the trade off of larger overall proof sizes \cite{Genes2025EfficientRecursiveSnark}. Likewise, Zecale demonstrates how recursive aggregation can substantially reduce verification overhead while preserving privacy in blockchain contexts \cite{Rondelet2020Zecale}. Despite these theoretical advantages, the deployment of recursive zkSNARKs in constrained, privacy critical IoT environments has not yet been evaluated.

This research therefore targets a gap in current understanding by empirically establishing when recursive zkSNARKs offer a measurable advantage compared to classical zkSNARKs under realistic IoT conditions (hardware limits, privacy objectives, communication constraints). Our benchmarks compare recursive systems to non‑recursive implementations using identical data and report only measured latency, memory, and proof‑size results to produce actionable guidance for real‑world system designers.

\section{Research Questions}

Our research is guided by the following primary questions:

\begin{enumerate}
    \item Under which conditions is the use of recursive SNARKs beneficial?
    \item What added value do recursive SNARKs provide in the context of privacy?
    \item From which data volume or computational complexity onwards are recursive SNARKs more efficient?
    \item Can empirical measurements on realistic IoT setups determine when recursion becomes advantageous?
    \item What are the privacy-performance trade-offs in recursive vs. standard SNARK systems?
\end{enumerate}

\section{Contributions}

This thesis makes the following key contributions:

\begin{enumerate}
    \item \textbf{Nova Implementation}: Complete implementation of Nova recursive SNARKs optimized for IoT data processing
    \item \textbf{Empirical Validation}: Comprehensive resource-constrained IoT evaluation
    \item \textbf{Performance Analysis}: Detailed benchmarking across multiple scenarios using real measurements only
    \item \textbf{Practical Guidelines}: Decision frameworks for choosing appropriate proof systems
\end{enumerate}

\section{Thesis Structure}

\noindent The thesis is organized into eight chapters that map directly to the research questions and the evaluation pipeline:
\begin{enumerate}
    \item \textbf{Introduction} (\cref{sec:intro}): Motivation, problem statement, research questions, contributions, and chapter roadmap.
    \item \textbf{Background} (\cref{sec:background}): Task-relevant overview of IoT aggregation privacy risks and zero-knowledge systems; emphasis on concepts required to interpret the later crossover analysis.
    \item \textbf{Related Work} (\cref{chap:related-work}): Positioning within IoT privacy aggregation and zero-knowledge literature; highlights the gap this thesis addresses; core concepts and trade-offs of recursive vs. non-recursive zk-SNARKs relevant to this study.
    \item \textbf{System Architecture} (\cref{chap:system-architecture}): End-to-end architecture and components; actors; data flow and threat model; how the project is structured and executed.
    \item \textbf{Implementation} (\cref{chap:implementation}): Pipelines, tooling, measurement harness, reproducibility, and limitations.
    \item \textbf{Empirical Results and Analysis} (\cref{chap:empirical-results}): Integrated results covering crossover validation, temporal batching, sensitivity analysis, device-level performance, and practical selection guidelines.
    \item \textbf{Discussion} (\cref{chap:discussion}): Interpretation of findings, decision framework for practitioners, and threats to validity.
    \item \textbf{Conclusion \& Future Work} (\cref{chap:conclusion}): Summary of contributions and directions for future research.
\end{enumerate}

\noindent This structure keeps the narrative focused on the central objective: reporting strictly empirical advantages of recursive SNARKs in IoT settings. Each part either introduces a necessary concept, contributes a component of the methodology, or reports measured results that directly answer the research questions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Background}
\label{sec:background}
\section{Privacy \& Data Aggregation in IoT}
Resource constrained devices in Internet of Things environments collect and transmit sensor data such as temperature, power usage or motion events. Aggregating this data can reduce communication load and storage overhead, but doing so without cryptographic guarantees can compromise data integrity or privacy. A review by Ali et al \cite{InayatAliPrivacyPreservingDataAggregation2018} shows that traditional data aggregation techniques may expose raw readings and remain vulnerable to inference or tampering, especially in constrained sensor networks. Solutions such as LiPI \cite{GoyalLiPI2022} propose lightweight data masking mechanisms, but they often trade off integrity verification or depend on trusted components. There is limited research on cryptographically verifiable aggregation tailored for resource limited IoT nodes, especially when continuous privacy preservation is required.

\section{Overview of Zero-Knowledge Proofs}
A zero-knowledge proof (ZKP) lets a prover convince a verifier that a statement is true without revealing any additional information beyond its truth \cite{goldwasserKnowledgeComplexityInteractive1985}. ZKPs exist in interactive and non-interactive forms.
zk-SNARKs are non-interactive arguments of knowledge with succinct proofs; in many constructions, proof size and verifier work are sublinear—often effectively constant—in the size of the computation, though they may depend on public input size and typically require a setup \cite{nitulescuZkSnarksAGentleIntroduction2021}. zk-SNARKs have seen prominent deployments, e.g., in Zerocash/Zcash \cite{bensassonZerocashDecentralizedAnonymous2014,hopwoodZcashProtocolSpecification}.
zk-STARKs are transparent (no trusted setup) and hash-based; they scale well and are plausibly post-quantum, but usually incur larger proofs and higher prover costs \cite{ben-sassonScalableZeroKnowledge2019}.
Bulletproofs provide short non-interactive proofs without trusted setup with logarithmic proof size for certain statements (e.g., range proofs); however, verification is generally more expensive than in SNARK systems for large circuits \cite{BulletproofsStanfordApplied}.
Other families (e.g., Sonic, Plonk/Halo variants) explore different trade-offs in universality, transparency, setup, and efficiency \cite{mallerSonicZeroKnowledgeSNARKs2019}.
A recent survey overviews applications and practical frameworks across domains \cite{ASurveyApplicationsZKP2024}.

\subsection*{Alternatives and PETs}
Beyond zk-SNARKs, other families and PETs exist: zk-STARKs are transparent and plausibly post-quantum, but typically have larger proof sizes and higher prover costs. Differential Privacy adds calibrated noise to protect individuals but trades utility for privacy \cite{dworkCalibratingNoiseSensitivity2006,dworkAlgorithmicFoundationsDifferential2013}. Secure Multi-Party Computation offers strong privacy without a trusted party, yet incurs substantial communication/latency overhead and does not inherently provide public verifiability \cite{yaoHowGenerateExchange1986,goldreichHowPlayANY1987,damgardMultipartyComputationSomewhat2012}. Given our goal (verifiable aggregation under device and bandwidth constraints), we focus on zk-SNARKs, specifically standard vs.\ recursive designs.

\subsection*{Why we do not include a non-ZK baseline}
Non-cryptographic pipelines can be faster, but they reveal raw inputs or rely on trust in the computing entity, violating our privacy and integrity requirements. Without zero-knowledge proofs, a verifier cannot simultaneously ensure input confidentiality and computational correctness \cite{goldwasserKnowledgeComplexityInteractive1985,katzIntroductionModernCryptography2007}. Therefore, we compare proof systems (standard vs. recursive zk-SNARKs) rather than including a non-ZK baseline as a candidate solution.

\section{Recursive ZKPs and Aggregation}
Recursive zero knowledge proofs stack or fold multiple proofs into a single succinct result. This enables efficient and scalable verification especially in streaming or multi step computation settings where multiple sub proofs are generated.

\subsection*{Definition of aggregation in this thesis}
We use the term \emph{aggregation} narrowly to denote computations over sets or windows of readings that reduce raw data to concise statistics or validity results (e.g. range validation, sum/mean/median, min/max). In our scope, privacy-preserving aggregation must (i) reveal nothing about individual readings beyond what is logically implied by the output, and (ii) enable verifiers to check correctness without access to raw inputs. These requirements motivate zero-knowledge approaches \cite{goldwasserKnowledgeComplexityInteractive1985,katzIntroductionModernCryptography2007} and connect directly to our circuits and pipeline in \cref{chap:implementation}.

\subsection{Principles and Benefits}
The core idea of recursive ZKPs is to verify a proof inside another proof, thus composing multiple statements into an incrementally verifiable chain. This approach is formalized in theories such as incrementally verifiable computation and proof folding schemes. Nova introduced an efficient folding scheme that absorbs complexity into a relaxed R1CS representation, dramatically reducing per proof cost while maintaining succinct final proofs \cite{NovaFoldingIVC2023}. This makes recursion especially powerful when many steps must be verified sequentially.

\subsection{Frameworks: Halo, Nova, Plonky2}
Halo, introduced by Bowe et al in 2019, pioneered recursive SNARK designs that do not require a trusted setup. It supports cycles of elliptic curves and recursive proof composition transparently \cite{boweRecursiveProofComposition2019}. Nova builds on similar ideas through an efficient folding based proof aggregation strategy and achieves state of the art performance in proof generation and succinctness \cite{NovaFoldingIVC2023, PantheonNovaBenchmark}. Plonky2 is a zk-STARK based system optimized by Polygon Zero for recursive workloads. It uses custom gates and deep arithmetic constraints to enable recursion at scale with high proving speed \cite{Plonky2ZKM2025, AnalysisPlonky2Protocol, IntroducingPlonky2, MayaZKBlogAggregationSummary}. All three systems allow continual chaining of proofs and compression into a single final proof, reducing verification overhead in multi step or streaming use cases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Related Work}
\label{chap:related-work}

\section{IoT Privacy and Data Aggregation}

The overlap between IoT privacy preservation and data aggregation has been extensively studied. Traditional approaches to IoT data aggregation often sacrifice privacy for efficiency, creating vulnerabilities in smart home and industrial deployments \cite{SmartMeterPrivacySurvey2023, AStudyOnPrivacyPreserving2021}.

\subsection{Privacy-Preserving IoT Aggregation}

Early work by Ali et al. demonstrated that conventional aggregation techniques expose raw sensor readings to inference attacks \cite{InayatAliPrivacyPreservingDataAggregation2018}. Solutions such as LiPI propose lightweight obfuscation mechanisms but often trade off integrity verification or depend on trusted components \cite{GoyalLiPI2022}.

Recent advances in differential privacy for IoT have shown promise but struggle with the continuous, high-frequency nature of sensor data. The challenge lies in balancing privacy preservation with the computational and energy constraints of IoT devices. Prior work rarely offers end-to-end, verifiable aggregation with measured crossover points under resource constraints; our study fills this empirical gap by reporting only measured results and explicit crossover regimes.

\subsection*{Critical positioning}
Compared to prior surveys and systems, our contribution is explicitly empirical and hardware-aware: (i) we benchmark standard vs. recursive zk-SNARKs on identical logic and data under matched resource limits enforced via Docker (CPU/RAM constraints), and (ii) we report time/size crossovers under steady-state operation. Many prior works emphasize protocol design or transparency properties (e.g., STARKs) without quantifying when recursion is advantageous under constrained compute and memory. Our results provide that missing, practical boundary.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Alternatives and PETs: positioning.}
Complementary privacy-enhancing approaches offer different trade-offs for IoT aggregation. Differential Privacy protects individuals by adding calibrated noise but trades utility for privacy and does not provide integrity of computation \cite{dworkCalibratingNoiseSensitivity2006,dworkAlgorithmicFoundationsDifferential2013}. Secure Multiparty Computation can compute over distributed inputs without a trusted party but typically incurs higher latency and communication overhead that challenge constrained devices \cite{yaoHowGenerateExchange1986,goldreichHowPlayANY1987,damgardMultipartyComputationSomewhat2012}. Trusted Execution Environments provide hardware-backed isolation but introduce additional trust assumptions and potential side-channel risks. Our evaluation therefore focuses on zk-SNARKs (Standard vs. Nova) to obtain end-to-end verifiability with confidentiality and constant-size verification.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Recursive vs. Non-Recursive zk-SNARKs in Resource-Constrained Environments}
\label{sec:zk-snark-comparison}

\subsection{Fundamentals: Difference Between Recursive and Non-Recursive zk-SNARKs}

zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge) allow one to prove the correctness of a computation using a short cryptographic proof without revealing the underlying data. A non-recursive zk-SNARK refers to a single proof for a specific computation or statement. In contrast, recursive zk-SNARKs allow multiple proofs or computation steps to be composed into each other. In recursion, the output of one zk-SNARK is used as part of the input for the next, resulting in a single final proof that attests to the correctness of all intermediate computations \cite{innovationBlockchainScalabilityGuide}. This is also known as incrementally verifiable computation (IVC): the prover produces a proof for each computation step that confirms both the correctness of that step and that the previous step was correctly verified \cite{bellachiaVerifBFLLeveragingZkSNARKs2025}. Through this composition, iterative or sequential computations can be securely chained.

A well-known example of recursive zk-SNARKs is Nova, which is based on a folding scheme. Nova folds a long computation into an ongoing recursive proof and only generates the final zk-SNARK at the end \cite{ElHajj2024BenchmarkStudy}. As a result, the expensive zk-SNARK generation occurs only once—regardless of how many steps were involved in the computation. Systems such as Halo or Nova have demonstrated that recursive zk-SNARKs can be built without a trusted setup, making them suitable for real-world applications \cite{ElHajj2024BenchmarkStudy}.

\subsection{Efficiency, Computation Cost, and Latency}

The primary efficiency difference lies in the trade-off between proof generation and verification. In non-recursive zk-SNARKs, generating a single proof is expensive, but verifying that proof is very fast (often milliseconds). However, if multiple zk-SNARKs must be verified (e.g., many individual proofs), the overall verification time scales linearly. Recursive zk-SNARKs aim to drastically reduce this verification overhead by aggregating all claims into a single proof \cite{innovationBlockchainScalabilityGuide}. Thus, the final verification time remains essentially constant, regardless of the number of individual steps or proofs involved.

On the proving side, recursive SNARKs introduce some overhead, since each new proof must verify the previous one, increasing the number of constraints. In traditional constructions (e.g., Groth16), verifying a SNARK inside a SNARK was costly. Modern systems like Nova optimize this by delaying the expensive zk-SNARK compression to the end \cite{ElHajj2024BenchmarkStudy}. Nova works in two stages: it first builds an ongoing recursive proof and then applies a final zk-SNARK compression. This final step incurs a fixed cost, regardless of how many steps were folded in. Hence, the final verification time remains constant, while the proof generation time increases roughly linearly with the number of steps. Latency may increase moderately, since the system waits until the end to compress the accumulated proofs.

Proof size is another major advantage. While a typical Groth16 proof is constant in size, producing many individual proofs results in linear growth in storage or transmission. Recursive SNARKs produce one final compact proof whose size is largely independent of the number of inputs \cite{innovationBlockchainScalabilityGuide}.

\subsection{Scalability}
Recursive zk-SNARKs are most beneficial when dealing with large-scale computations or proof aggregation. For small or one-time computations, a single non-recursive proof is often more efficient, as the recursive overhead may not be justified.

Empirical studies indicate that even at modest batch sizes (a few dozen proofs), recursion can become advantageous. For example, in a decentralized IoT setting, Nova required only \textasciitilde3.6 seconds to aggregate and verify 10 digital signatures, whereas a non-recursive method using Risc0 took \textasciitilde369 seconds—over 100$\times$ slower \cite{bojicburgosDecentralizedIoTData2024}. The gap grows with more inputs. Another study showed that Nova could verify 100 signatures in 7.1 seconds, whereas a previous method based on homomorphic encryption and ECDSA took over 50 seconds to verify just 64 signatures \cite{bojicburgosDecentralizedIoTData2024}. These results suggest that at batch sizes of a few dozen, recursive approaches can already be significantly more efficient.

Moreover, recursion reduces distributed verification overhead. Without recursion, each verifier must check all proofs. With recursion, only a single final proof needs to be verified. This makes the per-claim verification time negligible, since a constant cost is amortized over many claims \cite{bojicburgosDecentralizedIoTData2024}. The load is shifted from weak verifiers (e.g., IoT devices or smart contracts) to a single strong prover.

\subsection{Use in IoT and Smart-Home Scenarios}

IoT and smart-home environments impose strict constraints: sensors and embedded devices often have limited processing power, memory, and energy. zk-SNARK generation is typically too expensive to perform locally \cite{bojicburgosDecentralizedIoTData2024}. Even verification can overwhelm constrained devices. Therefore, many architectures follow a layered model with edge servers.

In this setup, IoT devices only collect and sign data. They then forward it to a nearby edge aggregator, which performs proof generation and aggregation \cite{bojicburgosDecentralizedIoTData2024}. Only the final proof or its hash is sent to a blockchain or central verifier. This eliminates the need for IoT devices to generate or verify SNARKs, saving energy and bandwidth.

Recursive zk-SNARKs are ideal for such scenarios, as they can aggregate continuous sensor streams into an ongoing proof. For instance, Nova has been used to aggregate and verify 100 sensor signatures into a single proof suitable for on-chain verification \cite{bojicburgosDecentralizedIoTData2024}. Verifying this proof took only \textasciitilde0.06\,s per signature (i.e., \textasciitilde6\,s total), even for low-powered verifiers.

Beyond signature verification, recursive SNARKs can prove compliance with rules over long periods, such as “no sensor exceeded a threshold for the past hour.” This streaming proof model allows incremental updates and compact final validation, ideal for constrained environments \cite{ElHajj2024BenchmarkStudy}.

Studies have even demonstrated recursive zk-SNARKs in advanced tasks like federated learning: each local training round and the global aggregation step are provably verified using Nova. In one setup, the global model proof took \textasciitilde81 seconds to generate and \textasciitilde0.6 seconds to verify \cite{bellachiaVerifBFLLeveragingZkSNARKs2025}. This shows that the cost is mostly on the proving side, which can be offloaded to strong devices.

\subsection{Summary and Implications for Architecture}
Recursive zk-SNARKs offer compelling benefits for scaling zero-knowledge applications in IoT scenarios. They enable aggregation of multiple computations or data streams into a single compact proof, which reduces memory, bandwidth, and verification cost—key concerns in resource‑constrained environments. Our system architecture (\cref{chap:system-architecture}) therefore places proving at an edge aggregator, defines batching policies that drive into empirically observed crossover regimes, and adopts metrics (proof time, verification time, proof size, and device load) that operationalize these trade‑offs. The following chapter translates these implications into a concrete architecture and methodology and specifies the evaluation setup used to validate them in practice.

\chapter{System Architecture}
\label{chap:system-architecture}

\begin{figure}[H]
\centering
\resizebox{0.95\linewidth}{!}{%
\begin{tikzpicture}[
  font=\small,
  box/.style={draw, rounded corners=2pt, align=center, minimum width=3.8cm, minimum height=1.1cm, fill=blue!3},
  group/.style={draw, dashed, rounded corners=3pt, inner sep=6pt},
  arrow/.style={-Latex, thick}
]
% IoT devices (left)
\node[box] (dev1) at (0,0.9) {IoT device};
\node[box, below=2mm of dev1] (dev2) {IoT device};
\node[box, below=2mm of dev2] (dev3) {IoT device};
\node[group, fit=(dev1)(dev3), label=above:{Device domain}] (devdom) {};


% Edge aggregator (middle)
\node[box, right=3.2cm of dev2] (ingest) {Data collection \& batching};
\node[box, below=4mm of ingest] (prover) {Proof generator \\ (Standard or Recursive)};
\node[group, fit=(ingest)(prover), label=above:{Edge domain}] (edgedom) {};

% Verifier / consumer (right)
\node[box, right=3.6cm of prover] (verifier) {Verifier / Consumer};
\node[group, fit=(verifier), label=above:{Consumer domain}] (condom) {};

% Connections
\draw[arrow] (devdom.east) -- node[above]{signed readings} (ingest.west);
\draw[arrow] (prover.east) -- node[above]{aggregate + proof} (verifier.west);
% no storage/contract in minimal architecture
\end{tikzpicture}%
}
\caption{System Architecture and logic}
\label{fig:system-overview}
\end{figure}

\paragraph{Component terminology (Figure~\ref{fig:system-overview}).}
\begin{itemize}
  \item \textbf{Domain}: \emph{Device domain} groups IoT devices, \emph{Edge domain} hosts data collection/batching and proving, \emph{Consumer domain} contains verifiers and consuming services.
  \item \textbf{Signed readings}: Sensor measurements signed by the originating device (with timestamp/ID); ensures authenticity and integrity of inputs to aggregation.
  \item \textbf{Data collection \& batching}: Edge component that verifies signatures, deduplicates/orders events, buffers them, and forms fixed windows/batches as circuit inputs.
  \item \textbf{Proof generator (Standard or Recursive)}: Cryptographic stage creating a zk‑proof that the published aggregate(s) were computed correctly from the private inputs; implemented once with non‑recursive SNARKs and once with recursion.
  \item \textbf{Aggregate + proof}: Public outputs (aggregates) together with the corresponding zero‑knowledge proof delivered to consumers.
  \item \textbf{Verifier / Consumer}: Validates proofs and uses the aggregates (dashboards, analytics, policy, billing, etc.).
  % Minimal architecture omits dedicated storage/contract components.
\end{itemize}

This chapter establishes the evaluation framework used to compare standard and recursive zk-SNARKs in IoT environments and defines the system components at a technology-agnostic level. The architecture follows an edge-centric pattern \cite{shiEdgeComputingVision2016}.

\section{Threat Model and Security Assumptions}
\label{sec:threat-model}

The security analysis of our IoT aggregation system requires a comprehensive threat model that considers the capabilities and motivations of potential adversaries. Our threat model distinguishes between passive and active adversaries operating within the IoT aggregation environment, each presenting distinct security challenges and requiring appropriate countermeasures.

Passive adversaries possess the capability to observe all public communications between system components but lack the ability to modify or inject messages into the system. These adversaries attempt to infer private information from publicly available aggregates and proof transcripts. Examples include network eavesdroppers monitoring communication channels, curious verifiers attempting to extract additional information beyond what is explicitly revealed, and malicious consumers seeking to reverse-engineer individual sensor readings from aggregated data. The primary threat from passive adversaries lies in their ability to perform inference attacks on aggregated data, potentially revealing sensitive information about individual IoT devices or their usage patterns.

Active adversaries represent a more severe threat category, as they can modify, inject, or replay messages within the system. These adversaries may attempt to tamper with sensor data during transmission, compromise edge aggregators to manipulate aggregation processes, or forge proof results to create false verification outcomes. However, our architecture assumes that IoT devices themselves remain secure and maintain the integrity of their cryptographic keys for signing sensor readings. This assumption is reasonable given that IoT devices typically operate in controlled environments and can implement hardware-based security measures.

The system architecture provides comprehensive security guarantees across multiple dimensions. Data integrity is ensured through cryptographic verification of all published aggregates, guaranteeing that they represent correct computations over authentic sensor readings. Privacy preservation is maintained through zero-knowledge proofs that keep individual sensor readings confidential while revealing only aggregated results and proof validity. Authenticity is achieved through cryptographic signatures on all sensor readings by their originating devices, preventing unauthorized data injection. Finally, non-repudiation is provided through proof generation, which creates an immutable record of computation correctness that cannot be denied by any party.

\section{Data Flow and Processing Pipeline}
\label{sec:data-flow}

The data processing pipeline differs significantly between standard and recursive zk-SNARK approaches, reflecting their fundamental architectural differences and performance characteristics.

\subsection{Standard SNARK Pipeline}
The standard zk-SNARK approach processes IoT readings individually, following a sequential workflow that emphasizes granular verification capabilities. The process begins when the edge aggregator receives signed readings from IoT devices, each containing sensor data authenticated through cryptographic signatures. Each reading's authenticity is subsequently verified using the corresponding device's public key, ensuring that only legitimate sensor data enters the aggregation pipeline. For each verified reading, a zk-SNARK proof is generated that demonstrates correct range validation or aggregation according to predefined circuit constraints. These individual proofs are then collected and transmitted to consumers, who must verify each proof separately to validate the entire dataset. This approach ensures that each sensor reading is individually verifiable, providing fine-grained integrity guarantees. However, the verification process requires linear time proportional to the number of readings, creating scalability challenges as batch sizes increase.

\subsection{Recursive SNARK Pipeline}
The Nova recursive approach processes readings in batches, employing a fundamentally different strategy that optimizes for large-scale aggregation scenarios. The initial data collection and signature verification phases remain identical to the standard approach, maintaining the same security guarantees for input authentication. However, the processing diverges significantly during step preparation, where readings are systematically grouped into steps of three values each, with zero-padding applied as necessary to ensure consistent step sizes. This batching strategy enables Nova to fold multiple steps into a single ongoing proof through its efficient folding mechanism, dramatically reducing the computational overhead associated with individual proof generation. The recursive proof generation process accumulates computational claims across multiple steps, creating an incrementally verifiable computation chain. A final zk-SNARK compression stage transforms this accumulated proof into a single succinct proof that encapsulates the correctness of all processing steps. The verification process requires consumers to verify only one final proof regardless of input size.

\section{Component Interactions and Interfaces}
\label{sec:component-interactions}

The system architecture relies on well-defined interfaces and communication protocols between its major components, ensuring secure and efficient data flow while maintaining the integrity and privacy guarantees of the aggregation process.

\subsection{Device-to-Edge Communication}
IoT devices communicate with edge aggregators through a standardized protocol designed to ensure data authenticity and prevent replay attacks. Each sensor reading transmitted to the edge aggregator contains a comprehensive message format that includes the device identifier and timestamp for temporal ordering, the sensor value converted to an integer representation suitable for zero-knowledge circuit processing, a cryptographic signature generated using the device's private key for authentication, and a sequence number that provides replay protection against malicious message repetition. The communication protocol employs ECDSA signatures for authentication, ensuring that only devices with valid cryptographic credentials can submit readings to the aggregation system. The edge aggregator maintains a whitelist of authorized device public keys, enabling efficient verification of incoming messages while preventing unauthorized data sources from polluting the aggregation pipeline. Error handling mechanisms are implemented to reject messages that fail signature verification, while network timeouts trigger automatic retransmission with exponential backoff to handle temporary communication failures gracefully.

\subsection{Edge-to-Consumer Communication}
The edge aggregator transmits processed results to consumers through a protocol that varies according to the proof system employed. For standard SNARK implementations, the transmission includes an array of individual proofs accompanied by their corresponding aggregated results, enabling consumers to verify each reading independently. For recursive SNARK implementations, the transmission contains a single compressed proof along with the final aggregated result, significantly reducing the communication overhead while maintaining equivalent verification capabilities. The verification interface provides consumers with public inputs in the form of aggregates and their associated proofs, enabling complete verification of computation correctness without requiring access to private sensor readings. Each transmission includes comprehensive timing metadata that captures proof generation and processing durations, facilitating performance analysis and system optimization across different batch sizes and hardware configurations.

\section{Scalability and Performance Considerations}
\label{sec:scalability}

The scalability characteristics of our IoT aggregation system determine its applicability to large-scale deployments and influence the architectural decisions necessary to support growing data volumes and processing requirements.

\subsection{Horizontal Scaling}
The architecture supports multiple edge aggregators to achieve increased throughput and improved fault tolerance in large-scale deployments. Load balancing strategies enable IoT devices to be distributed across multiple edge aggregators based on geographic proximity, computational capacity, or current system load conditions. This distribution approach reduces the computational burden on individual aggregators while providing redundancy against single points of failure. Distributed verification capabilities allow consumers to verify proofs from multiple aggregators independently, enabling parallel processing that can significantly improve overall system throughput. Each aggregator maintains its own independent proof chain, ensuring that verification results remain consistent across the entire system while preventing cross-contamination between different aggregation processes. This horizontal scaling approach is particularly beneficial for recursive SNARK implementations, where the constant-size proof characteristics enable efficient parallel verification of proofs from multiple sources.

\subsection{Vertical Scaling}
Individual system components can be scaled vertically through increased computational resources, though our empirical evaluation reveals important limitations to this approach. Edge aggregators equipped with more powerful hardware can process larger batches and generate proofs faster, potentially reducing latency and improving throughput. However, our experiments demonstrate diminishing returns beyond certain resource thresholds, particularly when memory bandwidth becomes the limiting factor rather than computational capacity. Consumer verification processes can be accelerated through specialized hardware implementations or optimized software algorithms, though our evaluation focuses primarily on resource-constrained scenarios that reflect typical edge computing environments. The relationship between resource allocation and performance improvement is not linear, creating optimization challenges that require careful analysis of specific deployment requirements and constraints.

\section{Measurement Framework}
Our benchmarking framework provides comprehensive evaluation capabilities that enable rigorous empirical analysis of proof system performance characteristics. All measurements are conducted under identical conditions using Docker containers and deterministic input data, ensuring that performance comparisons reflect genuine differences between proof systems rather than experimental artifacts. The framework measures proof generation time, verification time, proof size, and memory usage across different number of data sizes, providing comprehensive performance profiles that inform practical deployment decisions. Automated crossover analysis capabilities detect performance crossover points between standard and recursive approaches, enabling systematic identification of the conditions under which each approach provides optimal performance. This measurement framework forms the foundation for the empirical evaluation presented in subsequent chapters, providing the quantitative basis for practical guidance on proof system selection in IoT aggregation scenarios.

\chapter{Implementation}
\label{chap:implementation}
\section{Environment and Hardware Profile}
\label{sec:env-hw}

We executed all experiments under a resource-constrained profile intended to simulate realistic IoT edge environments. 
Specifically, we used Docker containers with enforced limits on CPU, memory, and swap space to approximate the hardware characteristics of IoT-devices, such as Raspberry Pi's.

\begin{itemize}
  \item \textbf{CPU}: fixed 0.5 logical core
  \item \textbf{RAM}: fixed 1\,GB
  \item \textbf{Swap}: 1\,GB (additional virtual memory)
  \item \textbf{Storage}: SSD, same filesystem for fair I/O caching behavior
\end{itemize}

These settings are chosen based on typical Raspberry Pi-class device specifications, which often provide ~1-4 GB RAM and single-to-quad-core CPUs in edge deployments. For example, Gupta \& Nahrstedt \cite{guptaPerformanceCharacterizationContainers2025} empirically evaluate similar IoT devices and show that Docker containers on hardware with ~1 GB RAM suffer measurable overheads in latency and I/O under constrained CPU/RAM settings.\\

\noindent Host platform (for emulation):
\begin{table}[H]
  \centering
  \begin{tabular}{ll}
    \hline
    Component & Specification \\
    \hline
    CPU & AMD Ryzen 7 7800X3D (8 cores, 16 threads; base \SI{4.2}{GHz}) \\
    RAM & \SI{32}{GB} DDR5 @ \SI{6000}{MT/s} (2\,\texttimes{} DIMM) \\
    GPU & NVIDIA GeForce RTX 4070 SUPER (12\,GB VRAM) \\
    Virtualization & Windows 11 + WSL2 (Ubuntu kernel 6.6.87.2) \\
    \hline
  \end{tabular}
  \caption{Host platform used to simulate IoT-like environments under resource constraints via Docker/cgroups.}
\end{table}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Requirements (load once in the preamble):
% \usepackage{graphicx}
% \usepackage{booktabs}
% \usepackage{siunitx}
% \usepackage{hyperref}
% \usepackage{caption}
% \sisetup{round-mode=places,round-precision=2,detect-weight=true,detect-inline-weight=math}

\chapter{Results and Analysis}
\label{chap:empirical-results}

This chapter presents the empirical evaluation of Standard zk-SNARKs versus recursive zk-SNARKs for IoT data aggregation. The analysis reveals significant performance differences between the two approaches.


\section{Performance Results}
\label{sec:performance-results}

\subsection{Docker Environment Results (Resource-Constrained)}

Table \ref{tab:docker-performance} shows the performance results under Docker resource limitations, which simulate typical IoT edge device constraints.

\begin{table}[H]
\centering
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Readings} & \textbf{Standard (s)} & \textbf{Nova (s)} & \textbf{Winner} & \textbf{Ratio} \\
\midrule
50 & 4.67 & 37.09 & Standard & 7.9\texttimes{} \\
60 & 5.48 & 38.67 & Standard & 7.1\texttimes{} \\
70 & 6.55 & 40.90 & Standard & 6.2\texttimes{} \\
80 & 7.44 & 42.80 & Standard & 5.8\texttimes{} \\
90 & 8.47 & 43.97 & Standard & 5.2\texttimes{} \\
100 & 9.13 & 46.66 & Standard & 5.1\texttimes{} \\
\bottomrule
\end{tabular}
\caption{Performance comparison under Docker resource constraints (CPU: 0.5, RAM: 1GB)}
\label{tab:docker-performance}
\end{table}

Under resource-constrained conditions, Standard SNARKs consistently outperform Nova by a factor of 5-8\texttimes{}, with no crossover point observed. This suggests that Nova's recursive processing requires significantly more computational resources than available in typical IoT edge devices.

\subsection{Native Environment Results (Full Resources)}

Table \ref{tab:native-performance} presents the performance results without resource limitations, revealing a fundamentally different performance profile.

\begin{table}[H]
\centering
\begin{tabular}{@{}lccccc@{}}
\toprule
\textbf{Readings} & \textbf{Standard (s)} & \textbf{Nova (s)} & \textbf{Winner} & \textbf{Ratio} \\
\midrule
50 & 8.16 & 9.60 & Standard & 1.18\texttimes{} \\
60 & 9.75 & 9.86 & Standard & 1.01\texttimes{} \\
70 & 11.62 & 10.27 & \textbf{Nova} & \textbf{1.13\texttimes{}} \\
80 & 13.15 & 10.47 & Nova & 1.26\texttimes{} \\
90 & 14.43 & 10.65 & Nova & 1.36\texttimes{} \\
100 & 16.32 & 10.87 & Nova & 1.50\texttimes{} \\
\bottomrule
\end{tabular}
\caption{Performance comparison with full system resources (no Docker limitations)}
\label{tab:native-performance}
\end{table}

The native environment reveals a clear crossover point at approximately 70 readings, where Nova begins to outperform Standard SNARKs. Beyond this point, Nova's advantage grows linearly with batch size, reaching 1.5\texttimes{} faster performance at 100 readings.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion}
\label{chap:discussion}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion \& Future Work}
\label{chap:conclusion}



\printbibliography

\end{document}
