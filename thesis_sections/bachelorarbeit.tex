\documentclass[english,bibtotoc,liststotoc,oneside,BCOR=5mm,DIV=12]{scrbook}
\recalctypearea

\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
\usepackage{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{positioning,fit,arrows.meta,backgrounds}
\usepackage{adjustbox} % für max width = \linewidth
\usepackage{booktabs}
\usepackage{siunitx}
\usepackage{csvsimple}   % moderne Version mit \csvautotabular
\usepackage{booktabs}
\usepackage{adjustbox}
\pgfplotsset{compat=1.18}
\usepackage{listings, color}
\usepackage{subcaption}
\usepackage[automark]{scrlayer-scrpage}
\setlength{\marginparwidth}{2cm}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit,backgrounds,shadows,decorations.pathmorphing,decorations.pathreplacing}
\usetikzlibrary{calc,intersections,through,backgrounds,matrix}
\usetikzlibrary{arrows.meta, calc, positioning, shapes.geometric}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{array}
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\usepackage[table]{xcolor}
\usepackage[most]{tcolorbox}
\tcbuselibrary{listings,skins}
% Neutral panel with teal accent for algorithms/notes
\newtcolorbox{algwithnotes}[1][]{enhanced,breakable,sharp corners,boxrule=0.6pt,
  colback=blue!3!white,colframe=black!20,borderline west={2pt}{0pt}{teal!70!black},
  title={#1},fonttitle=\bfseries}

% Listings style for nicer code blocks
\lstdefinestyle{codeblock}{%
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  framerule=0.5pt,
  backgroundcolor=\color{blue!5!white},
  rulecolor=\color{teal!70!black},
  numbers=left,
  numberstyle=\tiny,
  numbersep=16pt,
  xleftmargin=2.6em,
  framexleftmargin=2.0em
}
\lstset{style=codeblock}

% Theorem-like environments
\newtheorem{definition}{Definition}

\usepackage{booktabs}
\usepackage{csquotes}
\usepackage[backend=biber, style=ieee]{biblatex}
\addbibresource{bib/references.bib}

% Only number and list up to sections (no subsection/subsubsection numbering in ToC or headings)
\setcounter{secnumdepth}{1}
\setcounter{tocdepth}{1}

\clearpairofpagestyles
\chead[Verifiable Data Transformations in IoT Environments – Ramón Felipe Kühne]{Verifiable Data Transformations in IoT Environments – Ramón Felipe Kühne}
% Unified footer for all page styles (plain and scrheadings)
\cfoot[TU Berlin, 2025 \quad | \quad \thepage]{TU Berlin, 2025 \quad | \quad \thepage}
\KOMAoptions{headsepline=.4pt}
\renewcommand*{\chapterpagestyle}{scrheadings}
\pagestyle{scrheadings}

\graphicspath{{./img/}{../data/visualizations/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\frontmatter
\input{misc/titlepage}
    \thispagestyle{empty}
    \cleardoublepage
    
\input{misc/self-assertion}
    \thispagestyle{empty}
    \cleardoublepage

% Switch to arabic numbering for all following pages
\mainmatter
\pagenumbering{arabic}
\setcounter{page}{1}

\section*{Declaration of Authorship}
I hereby declare that I have written this thesis independently and have not used any sources or aids other than those stated. All passages taken directly or indirectly from the published or unpublished work of others have been identified as such. This thesis has not been submitted in substantially the same form to any other examination board and has not been published.

\clearpage

\section*{Abstract}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\clearpage
\cleardoublepage
\listoffigures
\clearpage
\listoftables
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{sec:intro}

\section{Motivation}
\label{sec:motivation}
IoT deployments such as smart home sensors, industrial monitors, and environmental sensing networks generate continuous high resolution time series data. To reduce communication and storage demands on resource constrained edge devices, this data is often aggregated in batches, for example via summation or averaging. Conventional aggregation lacks formal guarantees regarding data integrity and privacy \cite{SmartMeterPrivacySurvey2023, AStudyOnPrivacyPreserving2021}. Research has shown that even coarse patterns like hourly energy usage can expose private habits \cite{muellerGewinnungVerhaltensprofilenAm2010}. Aggregation pipelines that rely on unverified local computation are susceptible to tampering or omission, which undermines trust in reported values \cite{bohliPrivacyModelSmart2010aa}. This combination of emerging privacy threats and trust issues highlights the need for cryptographic verification mechanisms in IoT aggregation systems.

Global data production has exploded over the past decade. In 2010 approximately 2 zettabytes of data existed. By 2023 that number reached about 120 zettabytes. In 2024 it rose to approximately 147 zettabytes. Projections expect global data volume to grow further to 181 zettabytes by 2025 \cite{IDCExpect175, HowMuchData}. This dramatic increase magnifies the potential impact of large scale data breaches. In the healthcare sector alone the number of breaches reported to U.S. authorities reached 725 in 2023, exposing over 133 million records \cite{alderDecember2023Healthcare2024}.

The proliferation of IoT devices further accelerates data generation and increases privacy risk. Smart thermostats, smart meters, wearable health trackers, voice assistants, and environmental sensors continuously collect sensor data, often without users’ full awareness. These devices shape daily life and generate intimate behavioral insights.

Because massive volumes of data are generated every moment and breaches are escalating, ensuring the integrity and confidentiality of aggregated data has become critically important. This motivates the development of cryptographic methods that can verify aggregated IoT data without compromising user privacy.

\section{Problem Statement}
\label{sec:problemstatement}
The central problem of this thesis has two main aspects. First, existing aggregation methods do not provide formal integrity guarantees. In practice, users cannot confirm that published aggregates include all raw sensor readings nor detect whether any data were omitted or modified during processing. Second, although zkSNARKs allow confidential proofs of correctness, classical non recursive approaches become increasingly inefficient when used repeatedly for continuous streaming data. The core inefficiency stems from computational complexity, especially during witness generation, which can easily become a bottleneck on IoT hardware with limited resources \cite{ElHajj2024BenchmarkStudy}. In addition, many traditional zkSNARK protocols depend on a trusted setup and do not allow parallel processing, which limits their scalability in IoT use cases.

Recursive zkSNARKs present a promising alternative. They support proof chaining across batches, so that verification cost is amortized rather than repeated. Recent systems such as GENES demonstrate substantial improvements in proving time and verification latency through recursive proof composition. However, these improvements sometimes come with the trade off of larger overall proof sizes \cite{Genes2025EfficientRecursiveSnark}. Likewise, Zecale demonstrates how recursive aggregation can substantially reduce verification overhead while preserving privacy in blockchain contexts \cite{Rondelet2020Zecale}. Despite these theoretical advantages, the deployment of recursive zkSNARKs in constrained, privacy critical IoT environments has not yet been evaluated.

This research therefore targets a gap in current understanding by empirically establishing when recursive zkSNARKs offer a measurable advantage compared to classical zkSNARKs under realistic IoT conditions (hardware limits, privacy objectives, communication constraints). Our benchmarks compare recursive systems to non‑recursive implementations using identical data and report only measured latency, memory, and proof‑size results to produce actionable guidance for real‑world system designers.

\section{Research Questions}

Our research is guided by the following primary questions:

\begin{enumerate}
    \item Under which conditions is the use of recursive SNARKs beneficial?
    \item What added value do recursive SNARKs provide in the context of privacy?
    \item From which data volume or computational complexity onwards are recursive SNARKs more efficient?
    \item Can empirical measurements on realistic IoT setups determine when recursion becomes advantageous?
    \item What are the privacy-performance trade-offs in recursive vs. standard SNARK systems?
\end{enumerate}

\section{Contributions}

This thesis makes the following key contributions:

\begin{enumerate}
    \item \textbf{Nova Implementation}: Complete implementation of Nova recursive SNARKs optimized for IoT data processing
    \item \textbf{Empirical Validation}: Comprehensive resource-constrained IoT evaluation
    \item \textbf{Performance Analysis}: Detailed benchmarking across multiple scenarios
    \item \textbf{Practical Guidelines}: Decision frameworks for choosing appropriate proof systems
\end{enumerate}

\section{Thesis Structure}

\noindent The thesis is organized into eight chapters that map directly to the research questions and the evaluation pipeline:
\begin{enumerate}
    \item \textbf{Introduction} (\cref{sec:intro}): Motivation, problem statement, research questions, contributions, and chapter roadmap.
    \item \textbf{Background} (\cref{sec:background}): Task-relevant overview of IoT aggregation privacy risks and zero-knowledge systems; emphasis on concepts required to interpret the later crossover analysis.
    \item \textbf{Related Work} (\cref{chap:related-work}): Positioning within IoT privacy aggregation and zero-knowledge literature; highlights the gap this thesis addresses; core concepts and trade-offs of recursive vs. non-recursive zk-SNARKs relevant to this study.
    \item \textbf{System Architecture} (\cref{chap:system-architecture}): End-to-end architecture and components; actors; data flow and threat model; how the project is structured and executed.
    \item \textbf{Implementation} (\cref{chap:implementation}): Pipelines, tooling, measurement harness, reproducibility, and limitations.
    \item \textbf{Empirical Results and Analysis} (\cref{chap:empirical-results}): Integrated results covering crossover validation, temporal batching, sensitivity analysis, device-level performance, and practical selection guidelines.
    \item \textbf{Discussion} (\cref{chap:discussion}): Interpretation of findings, decision framework for practitioners, and threats to validity.
    \item \textbf{Conclusion \& Future Work} (\cref{chap:conclusion}): Summary of contributions and directions for future research.
\end{enumerate}

\noindent This structure keeps the narrative focused on the central objective: reporting strictly empirical advantages of recursive SNARKs in IoT settings. Each part either introduces a necessary concept, contributes a component of the methodology, or reports measured results that directly answer the research questions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Background}
\label{sec:background}
\section{Privacy \& Data Aggregation in IoT}
Resource constrained devices in Internet of Things environments collect and transmit sensor data such as temperature, power usage or motion events. Aggregating this data can reduce communication load and storage overhead, but doing so without cryptographic guarantees can compromise data integrity or privacy. A review by Ali et al \cite{InayatAliPrivacyPreservingDataAggregation2018} shows that traditional data aggregation techniques may expose raw readings and remain vulnerable to inference or tampering, especially in constrained sensor networks. Solutions such as LiPI \cite{GoyalLiPI2022} propose lightweight data masking mechanisms, but they often trade off integrity verification or depend on trusted components. There is limited research on cryptographically verifiable aggregation tailored for resource limited IoT nodes, especially when continuous privacy preservation is required.

\section{Overview of Zero-Knowledge Proofs}
A zero-knowledge proof (ZKP) lets a prover convince a verifier that a statement is true without revealing any additional information beyond its truth \cite{goldwasserKnowledgeComplexityInteractive1985}. ZKPs exist in interactive and non-interactive forms.
zk-SNARKs are non-interactive arguments of knowledge with succinct proofs; in many constructions, proof size and verifier work are sublinear—often effectively constant—in the size of the computation, though they may depend on public input size and typically require a setup \cite{nitulescuZkSnarksAGentleIntroduction2021}. zk-SNARKs have seen prominent deployments, e.g., in Zerocash/Zcash \cite{bensassonZerocashDecentralizedAnonymous2014,hopwoodZcashProtocolSpecification}.
zk-STARKs are transparent (no trusted setup) and hash-based; they scale well and are plausibly post-quantum, but usually incur larger proofs and higher prover costs \cite{ben-sassonScalableZeroKnowledge2019}.
Bulletproofs provide short non-interactive proofs without trusted setup with logarithmic proof size for certain statements (e.g., range proofs); however, verification is generally more expensive than in SNARK systems for large circuits \cite{BulletproofsStanfordApplied}.
Other families (e.g., Sonic, Plonk/Halo variants) explore different trade-offs in universality, transparency, setup, and efficiency \cite{mallerSonicZeroKnowledgeSNARKs2019}.
A recent survey overviews applications and practical frameworks across domains \cite{ASurveyApplicationsZKP2024}.

\section{Verifiable Transformations in IoT Environments}

Verifiable transformations in IoT environments refer to cryptographic computations that process sensor data while maintaining both privacy and computational integrity guarantees. These transformations enable the verification of data processing correctness without revealing individual sensor readings, making them essential for privacy-preserving IoT aggregation systems.

\subsection{Definition and Requirements}

A verifiable transformation in IoT contexts must satisfy three fundamental requirements: (i) \emph{computational integrity}, ensuring that published results represent correct computations over authentic input data; (ii) \emph{privacy preservation}, preventing the disclosure of individual sensor readings beyond what is logically implied by the output; and (iii) \emph{verification efficiency}, enabling efficient proof verification even on resource-constrained devices.

\subsection{Circuit Logic and Cryptographic Components}

The circuit logic for IoT verifiable transformations typically involves several cryptographic components. First, \emph{device signature verification} ensures that each sensor reading originates from an authenticated IoT device using the device's public key. Second, \emph{computational integrity verification} proves that the aggregation function was applied correctly to the verified inputs. The circuit design distinguishes between \emph{public arguments} (device public keys, aggregated results, timestamps) and \emph{private arguments} (individual sensor readings, device private keys, intermediate computation states).

\subsection{General Transformation Types}

Our implementation demonstrates several classes of verifiable transformations applicable to IoT environments:

\begin{itemize}
\item \textbf{Range Validation}: Proving that sensor readings fall within acceptable bounds without revealing individual values
\item \textbf{Statistical Aggregation}: Computing sums, means, medians, or other statistics while maintaining input privacy
\item \textbf{Threshold Compliance}: Verifying that aggregated metrics meet predefined thresholds without exposing individual contributions
\item \textbf{Temporal Analysis}: Proving properties about data collected over time windows while preserving temporal privacy
\end{itemize}

These transformations form the foundation for privacy-preserving IoT data processing, enabling verifiable analytics while protecting individual device privacy.

\subsection*{Why we do not include a non-ZK baseline}
Non-cryptographic pipelines can be faster, but they reveal raw inputs or rely on trust in the computing entity, violating our privacy and integrity requirements. Without zero-knowledge proofs, a verifier cannot simultaneously ensure input confidentiality and computational correctness \cite{goldwasserKnowledgeComplexityInteractive1985,katzIntroductionModernCryptography2007}. Therefore, we compare proof systems (standard vs. recursive zk-SNARKs) rather than including a non-ZK baseline as a candidate solution.

\section{Recursive ZKPs and Aggregation}
Recursive zero knowledge proofs stack or fold multiple proofs into a single succinct result. This enables efficient and scalable verification especially in streaming or multi step computation settings where multiple sub proofs are generated.

\subsection*{Definition of aggregation in this thesis}
We use the term \emph{aggregation} narrowly to denote computations over sets or windows of readings that reduce raw data to concise statistics or validity results (e.g. range validation, sum/mean/median, min/max). In our scope, privacy-preserving aggregation must (i) reveal nothing about individual readings beyond what is logically implied by the output, and (ii) enable verifiers to check correctness without access to raw inputs. These requirements motivate zero-knowledge approaches \cite{goldwasserKnowledgeComplexityInteractive1985,katzIntroductionModernCryptography2007} and connect directly to our circuits and pipeline in \cref{chap:implementation}.

\subsection{Principles and Benefits}
The core idea of recursive ZKPs is to verify a proof inside another proof, thus composing multiple statements into an incrementally verifiable chain. This approach is formalized in theories such as incrementally verifiable computation and proof folding schemes. Nova introduced an efficient folding scheme that absorbs complexity into a relaxed R1CS representation, dramatically reducing per proof cost while maintaining succinct final proofs \cite{NovaFoldingIVC2023}. This makes recursion especially powerful when many steps must be verified sequentially.

\subsection{Frameworks: Halo, Nova, Plonky2}
Halo, introduced by Bowe et al in 2019, pioneered recursive SNARK designs that do not require a trusted setup. It supports cycles of elliptic curves and recursive proof composition transparently \cite{boweRecursiveProofComposition2019}. Nova builds on similar ideas through an efficient folding based proof aggregation strategy and achieves state of the art performance in proof generation and succinctness \cite{NovaFoldingIVC2023, PantheonNovaBenchmark}. Plonky2 is a zk-STARK based system optimized by Polygon Zero for recursive workloads. It uses custom gates and deep arithmetic constraints to enable recursion at scale with high proving speed \cite{Plonky2ZKM2025, AnalysisPlonky2Protocol, IntroducingPlonky2, MayaZKBlogAggregationSummary}. All three systems allow continual chaining of proofs and compression into a single final proof, reducing verification overhead in multi step or streaming use cases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Related Work}
\label{chap:related-work}

\section{IoT Privacy and Data Aggregation}

The overlap between IoT privacy preservation and data aggregation has been extensively studied. Traditional approaches to IoT data aggregation often sacrifice privacy for efficiency, creating vulnerabilities in smart home and industrial deployments \cite{SmartMeterPrivacySurvey2023, AStudyOnPrivacyPreserving2021}.

\subsection{Privacy-Preserving IoT Aggregation}

Early work by Ali et al. demonstrated that conventional aggregation techniques expose raw sensor readings to inference attacks \cite{InayatAliPrivacyPreservingDataAggregation2018}. Solutions such as LiPI propose lightweight obfuscation mechanisms but often trade off integrity verification or depend on trusted components \cite{GoyalLiPI2022}.

Recent advances in differential privacy for IoT have shown promise but struggle with the continuous, high-frequency nature of sensor data. The challenge lies in balancing privacy preservation with the computational and energy constraints of IoT devices. Prior work rarely offers end-to-end, verifiable aggregation with measured crossover points under resource constraints; our study fills this empirical gap by reporting only measured results and explicit crossover regimes.

\subsection*{Critical positioning}
Compared to prior surveys and systems, our contribution is explicitly empirical and hardware-aware: (i) we benchmark standard vs. recursive zk-SNARKs on identical logic and data under matched resource limits enforced via Docker (CPU/RAM constraints), and (ii) we report time/size crossovers under steady-state operation. Many prior works emphasize protocol design or transparency properties (e.g., STARKs) without quantifying when recursion is advantageous under constrained compute and memory. Our results provide that missing, practical boundary.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Recursive vs. Non-Recursive zk-SNARKs in Resource-Constrained Environments}
\label{sec:zk-snark-comparison}

\subsection{Fundamentals: Difference Between Recursive and Non-Recursive zk-SNARKs}

zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge) allow one to prove the correctness of a computation using a short cryptographic proof without revealing the underlying data. A non-recursive zk-SNARK refers to a single proof for a specific computation or statement. In contrast, recursive zk-SNARKs allow multiple proofs or computation steps to be composed into each other. In recursion, the output of one zk-SNARK is used as part of the input for the next, resulting in a single final proof that attests to the correctness of all intermediate computations \cite{innovationBlockchainScalabilityGuide}. This is also known as incrementally verifiable computation (IVC): the prover produces a proof for each computation step that confirms both the correctness of that step and that the previous step was correctly verified \cite{bellachiaVerifBFLLeveragingZkSNARKs2025}. Through this composition, iterative or sequential computations can be securely chained.

A well-known example of recursive zk-SNARKs is Nova, which is based on a folding scheme. Nova folds a long computation into an ongoing recursive proof and only generates the final zk-SNARK at the end \cite{ElHajj2024BenchmarkStudy}. As a result, the expensive zk-SNARK generation occurs only once—regardless of how many steps were involved in the computation. Systems such as Halo or Nova have demonstrated that recursive zk-SNARKs can be built without a trusted setup, making them suitable for real-world applications \cite{ElHajj2024BenchmarkStudy}.

\subsection{Efficiency, Computation Cost, and Latency}

The primary efficiency difference lies in the trade-off between proof generation and verification. In non-recursive zk-SNARKs, generating a single proof is expensive, but verifying that proof is very fast (often milliseconds). However, if multiple zk-SNARKs must be verified (e.g., many individual proofs), the overall verification time scales linearly. Recursive zk-SNARKs aim to drastically reduce this verification overhead by aggregating all claims into a single proof \cite{innovationBlockchainScalabilityGuide}. Thus, the final verification time remains essentially constant, regardless of the number of individual steps or proofs involved.

On the proving side, recursive SNARKs introduce some overhead, since each new proof must verify the previous one, increasing the number of constraints. In traditional constructions (e.g., Groth16), verifying a SNARK inside a SNARK was costly. Modern systems like Nova optimize this by delaying the expensive zk-SNARK compression to the end \cite{ElHajj2024BenchmarkStudy}. Nova works in two stages: it first builds an ongoing recursive proof and then applies a final zk-SNARK compression. This final step incurs a fixed cost, regardless of how many steps were folded in. Hence, the final verification time remains constant, while the proof generation time increases roughly linearly with the number of steps. Latency may increase moderately, since the system waits until the end to compress the accumulated proofs.

Proof size is another major advantage. While a typical Groth16 proof is constant in size, producing many individual proofs results in linear growth in storage or transmission. Recursive SNARKs produce one final compact proof whose size is largely independent of the number of inputs \cite{innovationBlockchainScalabilityGuide}.

\subsection{Scalability}
Recursive zk-SNARKs are most beneficial when dealing with large-scale computations or proof aggregation. For small or one-time computations, a single non-recursive proof is often more efficient, as the recursive overhead may not be justified.

Empirical studies indicate that even at modest batch sizes (a few dozen proofs), recursion can become advantageous. For example, in a decentralized IoT setting, Nova required only \textasciitilde3.6 seconds to aggregate and verify 10 digital signatures, whereas a non-recursive method using Risc0 took \textasciitilde369 seconds—over 100$\times$ slower \cite{bojicburgosDecentralizedIoTData2024}. The gap grows with more inputs. Another study showed that Nova could verify 100 signatures in 7.1 seconds, whereas a previous method based on homomorphic encryption and ECDSA took over 50 seconds to verify just 64 signatures \cite{bojicburgosDecentralizedIoTData2024}. These results suggest that at batch sizes of a few dozen, recursive approaches can already be significantly more efficient.

Moreover, recursion reduces distributed verification overhead. Without recursion, each verifier must check all proofs. With recursion, only a single final proof needs to be verified. This makes the per-claim verification time negligible, since a constant cost is amortized over many claims \cite{bojicburgosDecentralizedIoTData2024}. The load is shifted from weak verifiers (e.g., IoT devices or smart contracts) to a single strong prover.

\subsection{Use in IoT and Smart-Home Scenarios}

IoT and smart-home environments impose strict constraints: sensors and embedded devices often have limited processing power, memory, and energy. zk-SNARK generation is typically too expensive to perform locally \cite{bojicburgosDecentralizedIoTData2024}. Even verification can overwhelm constrained devices. Therefore, many architectures follow a layered model with edge servers.

In this setup, IoT devices only collect and sign data. They then forward it to a nearby edge aggregator, which performs proof generation and aggregation \cite{bojicburgosDecentralizedIoTData2024}. Only the final proof or its hash is sent to a blockchain or central verifier. This eliminates the need for IoT devices to generate or verify SNARKs, saving energy and bandwidth.

Recursive zk-SNARKs are ideal for such scenarios, as they can aggregate continuous sensor streams into an ongoing proof. For instance, Nova has been used to aggregate and verify 100 sensor signatures into a single proof suitable for on-chain verification \cite{bojicburgosDecentralizedIoTData2024}. Verifying this proof took only \textasciitilde0.06\,s per signature (i.e., \textasciitilde6\,s total), even for low-powered verifiers.

Beyond signature verification, recursive SNARKs can prove compliance with rules over long periods, such as “no sensor exceeded a threshold for the past hour.” This streaming proof model allows incremental updates and compact final validation, ideal for constrained environments \cite{ElHajj2024BenchmarkStudy}.

Studies have even demonstrated recursive zk-SNARKs in advanced tasks like federated learning: each local training round and the global aggregation step are provably verified using Nova. In one setup, the global model proof took \textasciitilde81 seconds to generate and \textasciitilde0.6 seconds to verify \cite{bellachiaVerifBFLLeveragingZkSNARKs2025}. This shows that the cost is mostly on the proving side, which can be offloaded to strong devices.

\subsection{Summary and Implications for Architecture}
Recursive zk-SNARKs offer compelling benefits for scaling zero-knowledge applications in IoT scenarios. They enable aggregation of multiple computations or data streams into a single compact proof, which reduces memory, bandwidth, and verification cost—key concerns in resource‑constrained environments. Our system architecture (\cref{chap:system-architecture}) therefore places proving at an edge aggregator, defines batching policies that drive into empirically observed crossover regimes, and adopts metrics (proof time, verification time, proof size, and device load) that operationalize these trade‑offs. The following chapter translates these implications into a concrete architecture and methodology and specifies the evaluation setup used to validate them in practice.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{System Architecture}

\label{chap:system-architecture}

\section{Goals and Scope}
This chapter specifies the architecture of our privacy-preserving IoT proving pipeline. The goal is to prove properties of sensor data (range checks and aggregations) without revealing the raw values. We use zk-SNARKs for standard proving and Nova for recursive batching. Transport confidentiality and channel authentication are out of scope and can be provided independently (e.g., TLS).

\section{Actors and Trust Model}
We distinguish the following actors:
- \textbf{IoT Device (Prover source)}: produces readings and holds the device private key.
- \textbf{Key Registry / PKI (Issuer / CA)}: issues and publishes device certificates (public keys).
- \textbf{Edge Orchestrator}: verifies device certificate and reading signatures, prepares public/private inputs, triggers proving.
- \textbf{Prover / Nova Combiner}: runs proof generation (standard or Nova+compression).
- \textbf{Verifier (Utility)}: verifies proofs using the verification key.
- \textbf{Consumer}: consumes only verified aggregates/results.

Trust assumptions:
- The CA root is trusted by the orchestrator/verifier.
- The device private key never leaves the device. The device certificate is signed by the CA.
- The orchestrator retains the proving key; the verification key is distributed to verifiers.

\section{Key Management}
- \textbf{Device identity}: the device generates its keypair on-device and obtains a CA-signed certificate. In our implementation, a local CA is created for reproducibility (files in \texttt{data/device_keys/}).
- \textbf{Proof system keys}:
  - \textit{proving.key}: created and stored locally by the orchestrator during ZoKrates setup; never shared.
  - \textit{verification.key}: exported and provided to the verifier for proof checking.

\section{System Overview}
Figure~\ref{fig:system-overview} shows the end-to-end actors and message flow (PKI bootstrap, signature verification, proving, verification). Figure~\ref{fig:verifiable-transformations} abstracts the verifiable transformation: public policy and private readings flow into the circuit, which yields a proof verified with the verification key.


\begin{figure}[H]
\centering
\resizebox{0.98\textwidth}{!}{%
\begin{tikzpicture}[
  scale=0.8, transform shape,
  lane/.style={draw, fill=gray!8, minimum width=3.7cm, minimum height=24cm},
  task/.style={draw, fill=white, rounded corners, minimum width=3.1cm, minimum height=0.95cm, font=\scriptsize, align=center},
  opt/.style={task, dashed},
  note/.style={draw, fill=gray!5, rounded corners, font=\scriptsize, align=left, minimum width=5.0cm},
  arrow/.style={-{Stealth[length=2.4mm,width=1.4mm]}, thick}
]
\node[lane] (L0) at (-4,0) {}; \node[above] at (L0.north) {Key Registry / PKI};
\node[lane] (L1) at ( 0,0) {}; \node[above] at (L1.north) {IoT Device};
\node[lane] (L2) at ( 4,0) {}; \node[above] at (L2.north) {Edge Orchestrator};
\node[lane] (L3) at ( 8,0) {}; \node[above] at (L3.north) {Prover / Nova};
\node[lane] (L4) at (12,0) {}; \node[above] at (L4.north) {Verifier};
\node[lane] (L5) at (16,0) {}; \node[above] at (L5.north) {Consumer};

\node[task] (d0) at (0,9.0)  {Generate device keypair\\(private stays on device)};
\node[task] (k1) at (-4,8.0) {Sign device certificate (Issuer/CA)};
\node[task] (k2) at (-4,7.0) {Publish device certificate + CA root};

\node[task] (d1) at (0,6.0)  {Generate sensor data};
\node[task] (d2) at (0,5.0)  {Sign payload (Ed25519)};

\node[task] (a0) at (4,4.2)  {Load CA root + device cert};
\node[task] (a1) at (4,3.2)  {Verify device certificate};
\node[task] (a2) at (4,2.2)  {Verify device signature (reading)};
\node[task] (a3) at (4,1.2)  {Setup ZoKrates (once)\\Manage proving.key \\ Export verification.key};
\node[task] (a4) at (4,0.2)  {Apply computation + ZK proof\\(range, min/max, median, …)};
\node[opt]  (a5) at (4,-0.8) {Prepare Nova inputs\\(init.json, steps.json)};

\node[task] (p1) at (8,-2.0) {Standard: generate SNARK proof};
\node[opt]  (p2) at (8,-3.4) {Nova: prove + compress};

\node[task] (v0) at (12,-4.6) {Import verification.key};
\node[task] (v1) at (12,-5.8) {Verify SNARK proof};
\node[opt]  (v2) at (12,-7.0) {Verify Nova compressed proof};

\node[task] (c1) at (16,-8.6) {Receive verified result / aggregate};

\draw[arrow] (d0) -- node[above,font=\scriptsize] {0a} (k1);
\draw[arrow] (k1) -- node[above,font=\scriptsize] {0b} (k2);
\draw[arrow] (k2) -- node[above,font=\scriptsize] {0c} (a0);

\draw[arrow] (d1) -- node[above,font=\scriptsize] {1} (d2);
\draw[arrow] (d2) -- node[above,font=\scriptsize] {2} (a2);

\draw[arrow] (a0) -- node[right,font=\scriptsize] {3} (a1);
\draw[arrow] (a1) -- node[right,font=\scriptsize] {4} (a2);
\draw[arrow] (a2) -- node[right,font=\scriptsize] {5} (a3);
\draw[arrow] (a3) -- node[right,font=\scriptsize] {6} (a4);

\draw[arrow] (a4) -- node[above,font=\scriptsize] {7} (p1);
\draw[arrow] (p1) -- node[above,font=\scriptsize] {8} (v0);
\draw[arrow] (v0) -- node[above,font=\scriptsize] {9} (v1);
\draw[arrow] (v1) -- node[above,font=\scriptsize] {10} (c1);

\draw[arrow] (a4) -- node[right,font=\scriptsize] {7a} (a5);
\draw[arrow] (a5) -- node[left,font=\scriptsize]  {8a} (p2);
\draw[arrow] (p2) -- node[left,font=\scriptsize]  {9a} (v2);
\draw[arrow] (v2) -- node[above,font=\scriptsize] {10a} (c1);

\node (center) at (current bounding box.south) {};
\node[note, below left=0.8cm and 2.2cm of center] {
  \textbf{Key management}\\
  Device private key: device\\
  Device certificate: signed by CA\\
  CA root: trusted by orchestrator/verifier\\
  Proving key: orchestrator-local\\
  Verification key: distributed to verifier};
\node[note, below right=0.8cm and 2.2cm of center] {
  \textbf{Circuit I/O}\\
  Public: policy bounds, metadata, timeframe\\
  Private: sensor reading(s) (witness)\\
  Guarantee: computational integrity of transformation};
\end{tikzpicture}
}
\caption{System Architecture with PKI, proving, and verification flows.}
\label{fig:system-overview}
\end{figure}

\begin{figure}[H]
\centering
\resizebox{0.98\textwidth}{!}{%
\begin{tikzpicture}[
  box/.style={draw, rounded corners, fill=white, minimum width=4.4cm, minimum height=1.0cm, align=center, font=\scriptsize},
  arrow/.style={-{Stealth[length=2.2mm,width=1.3mm]}, thick}
]
\node[box, fill=gray!10] (pub)   at (0,0)   {Public Inputs\\policy/meta/timeframe};
\node[box, fill=gray!10] (priv)  at (0,-2)  {Private Inputs (witness)\\sensor readings / aggregates};
\node[box] (circ)  at (6,-1) {ZoKrates Circuit: transformation f\\(range, min/max, median, sum-in-range, …)};
\node[box] (proof) at (12,-1){ZK-SNARK proof};
\node[box, fill=gray!10] (ver)   at (16,-1){Verifier\\verification.key};

\draw[arrow] (pub) -- (circ);
\draw[arrow] (priv) -- (circ);
\draw[arrow] (circ) -- (proof);
\draw[arrow] (proof) -- (ver);
\end{tikzpicture}
}
\caption{Verifiable Transformations: Public/Private I/O und Beweisfluss}
\label{fig:verifiable-transformations}
\end{figure}

\section{Verifiable Transformations}
We define a general transformation \(f\) over private readings with public policies:
- \textbf{Public inputs} (policy/meta/timeframe): bounds, time window identifiers, optional commitments/IDs.
- \textbf{Private inputs} (witness): sensor readings or aggregates derived from them.
- \textbf{Guarantee}: the circuit enforces the computational integrity of \(f\) on the private inputs for the given public policy.

Generic transformation set (domain-agnostic, demonstrated in our implementation):
- \textbf{Range / Threshold}: prove reading or aggregate lies within \([min, max]\).
- \textbf{Min/Max}: prove correct minimum/maximum over a set of values.
- \textbf{Median}: prove correct median over a window.
- \textbf{Sum-in-range} (optional extension): prove \(\sum\) over a window is within a public range or equals a billed amount.
For our codebase, these map to circuits under \texttt{circuits/basic/} (e.g., \texttt{filter\_range.zok}, \texttt{min\_max.zok}, \texttt{median.zok}).

\section{Data Flow}
Top-down sequence (one action per lane level):
- Device: generate keypair (private stays on device); collect reading; sign payload (Ed25519).
- PKI: sign device certificate; publish device certificate and CA root.
- Orchestrator: load CA root and device certificate; verify certificate; verify reading signature; run ZoKrates setup once (create \textit{proving.key}, export \textit{verification.key}); apply computation \(f\) and prove.
- Prover: generate proof (standard) or \emph{Nova: prove + compress}.
- Verifier: import \textit{verification.key}; verify proof (standard or Nova compressed).
- Consumer: consume verified aggregate/result.

\section{Proving Pipelines}
\subsection{Standard zk-SNARK (Groth16)}
- One proof per reading or per sub-aggregate.
- Verifier time and proof count scale with the number of items.
- Trusted setup is circuit-specific.

\subsection{Recursive (Nova + optional Groth16 compression)}
- Readings are prepared as steps; multiple steps are folded into one proof.
- Optional compression produces one succinct proof for the entire batch.
- Reduces verification to a constant number of proofs (often one), at the cost of more complex proving.

\section{Implementation Mapping}
- \textbf{Edge Orchestrator}: \texttt{scripts/measure\_crossover\_real.py} (certificate + signature verification, input prep, proof orchestration, metrics).
- \textbf{Standard Prover/Verifier}: \texttt{src/proof\_systems/snark\_manager.py} (ZoKrates \texttt{compile/setup/compute-witness/generate-proof/verify}).
- \textbf{Recursive Prover/Verifier}: \texttt{src/proof\_systems/nova\_manager.py} (ZoKrates \texttt{nova prove/compress/verify}).
- \textbf{PKI bootstrap (local CA, device cert)}: \texttt{scripts/setup\_device\_and\_dummy\_data.py}.
- \textbf{Circuits}: \texttt{circuits/basic/} and \texttt{circuits/nova/}.

\section{Security Properties and Assumptions}
- \textbf{Confidentiality}: raw readings remain private; only proofs and public policy are shared.
- \textbf{Integrity}: zk-SNARKs ensure computational integrity of \(f\).
- \textbf{Authenticity}: device signatures verified using CA-signed device certificate.
- \textbf{Key protection}: proving key stays on orchestrator; device private key stays on device.
- \textbf{Assumptions}: trusted CA root; correct ZoKrates setup; honest-but-curious verifier.

\section{Performance Considerations}
- Reported metrics: proving time, verification time, proof size, edge memory footprint.
- Standard vs. Nova trade-off: standard has fine-grained proofs but many verifications; Nova amortizes verification to (near) constant, with additional proving overhead.

\section{Limitations and Extensions}
- Networking security (TLS), key rotation, CRL/OCSP, and Merkle commitments are out of scope.
- Future work: bind entire reading sets via commitment roots; integrate revocation; extend circuits (sum-in-range billing).

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}
\label{chap:implementation}
\section{Environment and Hardware Profile}
\label{sec:env-hw}

We executed all experiments under a resource-constrained profile intended to simulate realistic IoT edge environments. 
Specifically, we used Docker containers with enforced limits on CPU and memory to approximate the hardware characteristics of IoT-devices. For example:

\begin{itemize}
  \item \textbf{CPU}: fixed 0.5 logical core
  \item \textbf{RAM}: fixed 1\,GB
\end{itemize}

These settings are chosen based on typical Raspberry Pi-class device specifications, which often provide 0.5-4 GB RAM and single-to-quad-core CPUs in edge deployments. For example, Gupta \& Nahrstedt \cite{guptaPerformanceCharacterizationContainers2025} empirically evaluate similar IoT devices and show that Docker containers on hardware with ~1 GB RAM suffer measurable overheads in latency and I/O under constrained CPU/RAM settings.\\

\noindent Host platform (for emulation):
\begin{table}[H]
  \centering
  \begin{tabular}{ll}
    \hline
    Component & Specification \\
    \hline
    CPU & AMD Ryzen 7 7800X3D (8 cores, 16 threads; base \SI{4.2}{GHz}) \\
    RAM & \SI{32}{GB} DDR5 @ \SI{6000}{MT/s} (2\,\texttimes{} DIMM) \\
    GPU & NVIDIA GeForce RTX 4070 SUPER (12\,GB VRAM) \\
    Virtualization & Windows 11 + WSL2 (Ubuntu kernel 6.6.87.2) \\
    \hline
  \end{tabular}
  \caption{Host platform used to simulate IoT-like environments under resource constraints via Docker/cgroups.}
\end{table}

\begin{figure}[H]
\centering
\resizebox{0.95\textwidth}{!}{%
\begin{tikzpicture}[
    node distance=1.2cm and 2.2cm,
    process/.style={rectangle, draw, rounded corners, align=center, minimum width=3.8cm, minimum height=1cm, fill=gray!10},
    decision/.style={diamond, aspect=2, draw, align=center, minimum width=2.5cm, minimum height=1cm, fill=gray!10},
    data/.style={parallelogram, draw, align=center, minimum width=3.8cm, minimum height=1cm, fill=white},
    io/.style={trapezium, trapezium left angle=75, trapezium right angle=105, draw, align=center, minimum width=3.8cm, minimum height=1cm, fill=white},
    arrow/.style={->, thick},
    dashedarrow/.style={->, dashed, thick}
]

% Nodes
\node[process] (A) {run\_in\_docker.sh};
\node[process, below=of A] (B) {Build Docker image:\\ ZoKrates 0.8.8};
\node[process, below=of B] (C) {Run container with CPU/RAM limits};
\node[process, below=of C] (D) {Clean caches \\ Show NumPy version};
\node[process, below=of D] (E) {Setup device keys \\ + generate signed readings};
\node[process, below=of E] (F) {measure\_crossover\_real.py};
\node[process, below=of F] (G) {Load IoT readings \\ Verify Ed25519 signatures};
\node[process, below=of G] (H) {Compile + Setup ZoKrates \\ (filter\_range.zok)};
\node[decision, below=of H] (I) {For each reading count};
\node[process, below left=1.5cm and 3.8cm of I] (J) {Standard SNARK:\\ Witness → Prove → Verify};
\node[process, below right=1.5cm and 3.8cm of I] (K) {Nova:\\ Prepare init/steps.json → Prove → Compress → Verify};
\node[process, below=3.5cm of I] (L) {Aggregate metrics (means)};
\node[process, below=of L] (M) {Compute time/size advantage \\ Detect crossover point};
\node[data, below=of M] (N) {Write JSON/CSV \\ data/real\_measurements};
\node[process, right=3.5cm of N] (O) {Print summary with file paths};
\node[process, below=of N] (P) {plot\_crossover\_json.py → PNG \\ (data/visualizations)};

% Connections
\draw[arrow] (A) -- (B);
\draw[arrow] (B) -- (C);
\draw[arrow] (C) -- (D);
\draw[arrow] (D) -- (E);
\draw[arrow] (E) -- (F);
\draw[arrow] (F) -- (G);
\draw[arrow] (G) -- (H);
\draw[arrow] (H) -- (I);
\draw[arrow] (I.west) -- (J.north);
\draw[arrow] (I.east) -- (K.north);
\draw[arrow] (J.south) -- (L.west);
\draw[arrow] (K.south) -- (L.east);
\draw[arrow] (L) -- (M);
\draw[arrow] (M) -- (N);
\draw[arrow] (N.east) -- (O.west);
\draw[dashedarrow] (N.south) -- (P.north);

\end{tikzpicture}
}
\caption{Flow of the IoT zk-SNARK evaluation pipeline inside Docker.}
\end{figure}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Requirements (load once in the preamble):
% \usepackage{graphicx}
% \usepackage{booktabs}
% \usepackage{siunitx}
% \usepackage{hyperref}
% \usepackage{caption}
% \sisetup{round-mode=places,round-precision=2,detect-weight=true,detect-inline-weight=math}
% =========================
% RESULTS CHAPTER (custom captions per run)
% =========================

\chapter{Results and Analysis}
\label{chap:empirical-results}

% ====== PREAMBLE ADDITIONS (einmalig in die Präambel) ======
% \usepackage{graphicx}
% \usepackage{float}
% \usepackage{booktabs}
% \usepackage{adjustbox}
% \usepackage{csvsimple}
% % Optionale feine Tabelle:
% % \usepackage{pgfplotstable}

This chapter compares a Standard zk-SNARK pipeline with a recursive Nova zk-SNARK pipeline in resource-limited containers. Each run fixes CPU/RAM limits and sweeps the number of IoT readings $N$. Every overview plot shows: (i) total wall-clock time, (ii) total proof size, and (iii) the time-efficiency ratio \emph{Standard/Nova} (values $>1$ favor Nova). For each $N$ both pipelines process identical inputs. Nova builds an incrementally verifiable computation (IVC) and compresses to one succinct proof; Standard emits one Groth16 proof per instance. Transport security and device authentication are out of scope to isolate proving/verification cost.

\section{Results}

% ---- ONE MACRO PER RUN: custom title + custom limits + observation text + CSV table ----
\newcommand{\ResultRunCustom}[4]{%
  \subsection*{#2}
  \begin{figure}[H]
    \centering
    \includegraphics[width=\linewidth]{ergebnis/md_warm_nr#1/real_crossover_overview.png}
    \caption{#2 \;—\; Docker limitations: \texttt{#3}.}
    \label{fig:run-#1}
  \end{figure}

  #4

  % ---- CSV-Tabelle mit den Messwerten dieses Runs ----
  \begin{table}[H]
    \centering
    % Kurzfassung für List of Tables | Volltext unter der Tabelle
    \caption[Results — Run \##1]{Results — Run \##1 (limits: \texttt{#3})}
    \label{tab:run-#1-summary}
    \begin{adjustbox}{max width=\linewidth}
      \csvautotabular[
        separator=comma,
        head to column names,
        respect all
      ]{ergebnis/md_warm_nr#1/crossover_summary.csv}
    \end{adjustbox}
  \end{table}

  \vspace{0.75em}
}


% ===== RUNS (Limits je Run hier eintragen) =====
\ResultRunCustom{1}{Run \#1}{--cpus=0.5, --memory=1g}{
\textbf{Observation.} Standard is faster across $N\in[100,1000]$; the efficiency ratio remains $<1$. Nova’s compressed proof stays $\approx 70$\,KB; Standard grows roughly linearly ($\sim$0.85\,KB per reading). Size crossover at $\sim\!82$ readings; no time crossover here.
}

\ResultRunCustom{2}{Run \#2}{--cpus=1, --memory=2g}{
\textbf{Observation.} Same qualitative pattern up to $N=500$: Standard wins in time (ratio $\approx0.15\text{–}0.39$); Nova’s proof size is essentially constant ($\approx70$\,KB), Standard grows linearly. Size crossover $\approx 82$; no time crossover.
}

\ResultRunCustom{3}{Run \#3}{--cpus=1, --memory=4}{
\textbf{Observation.} Matches \#1–\#2. Time ratio stays below $1$ throughout; Nova is slower on the edge. Size crossover around $82$.
}

\ResultRunCustom{4}{Run \#4}{--cpus=1, --memory=8}{
\textbf{Observation.} Unchanged: Standard faster end-to-end; Nova produces a single stable proof. Size crossover $\approx 82$; no time crossover up to $N=500$.
}

\ResultRunCustom{5}{Run \#5}{--cpus=2, --memory=2}{
\textbf{Observation.} Time ratio rises with $N$ (Standard approaches Nova) but remains $<1$ for $N\le 500$. Proof-size behavior unchanged (Nova $\approx70$\,KB vs.\ linear Standard). Size crossover near $82$.
}

\ResultRunCustom{6}{Run \#6}{--cpus=4, --memory=2}{
\textbf{Observation.} \emph{Time crossover present:} the efficiency curve crosses $1$ at roughly $N\approx700$ (see plot), i.e., Nova overtakes Standard in total time beyond that point. Proof-size crossover remains around $82$.
}


\section{Cross-run synthesis}
Across runs \#1–\#7 three stable findings emerge:
\begin{enumerate}
  \item \textbf{Proof size.} Nova’s compressed proof remains essentially constant ($\approx70$\,KB) as $N$ grows, whereas Standard increases roughly linearly at $\sim0.85$\,KB per reading. Hence a size crossover appears around \[
\frac{70\,\text{KB}}{0.85\,\text{KB}} \approx 82~\text{Readings}\] in all runs.

  \item \textbf{Total time.} On constrained edge hardware, Standard is consistently faster for small–medium $N$. With larger $N$ or more favorable limits, the gap narrows; in run~\#7 the time-efficiency ratio crosses $1$ near $N\approx700$, after which Nova becomes faster.
  \item \textbf{Operational trade-off.} Nova minimizes verifier load (one constant-size proof) and can become time-competitive at larger $N$, but incurs higher proving overhead at small $N$. Standard minimizes edge proving time for small/mid batches but yields a linearly growing set of proofs.
\end{enumerate}

\section{Summary for the smart-home edge}
For a resource-limited hub aggregating frequent, low-payload readings, the better choice depends on the bottleneck: when edge CPU/RAM and latency dominate, Standard is preferable at small $N$; when consumer bandwidth/verification dominates—or when batches become large—Nova’s single succinct proof is advantageous and can even overtake Standard in total time once $N$ is sufficiently high (run~\#7).

\section{Appendix: compact table}
\begin{table}[H]
  \centering
  \begin{tabular}{lccc}
    \toprule
    Run & Size crossover & Time crossover & Qualitative verdict \\
    \midrule
    \#1 & $\approx 82$ & none (to $N{=}1000$) & Standard faster; Nova much smaller \\
    \#2 & $\approx 82$ & none (to $N{=}500$)  & Same trend as \#1 \\
    \#3 & $\approx 82$ & none (to $N{=}500$)  & Same trend as \#1 \\
    \#4 & $\approx 82$ & none (to $N{=}500$)  & Same trend as \#1 \\
    \#5 & $\approx 82$ & none (to $N{=}500$)  & Gap narrows; size still favors Nova \\
    \#6 & $\approx 82$ & none (to $N{=}500$)  & Ratio approaches $1$ at high $N$ \\
    \#7 & $\approx 82$ & $\approx 700$ & Nova overtakes in time at larger $N$ \\
    % \#8 & $\approx 82$ & (fill from plot) & (fill after plotting) \\
    \bottomrule
  \end{tabular}
  \caption{Crossover summary from runs \#1–\#7.}
  \label{tab:crossover-summary}
\end{table}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion}
\label{chap:discussion}

\section{Alternative Privacy-Enhancing Technologies}

While our evaluation focuses on zk-SNARKs for verifiable IoT aggregation, several alternative privacy-enhancing technologies (PETs) offer different trade-offs in similar contexts. Understanding these alternatives helps position our contribution within the broader landscape of privacy-preserving IoT systems.

\subsection{Complementary PETs and Their Trade-offs}

\textbf{Differential Privacy} protects individuals by adding calibrated noise to aggregated results, but sacrifices utility and does not guarantee computational integrity \cite{dworkCalibratingNoiseSensitivity2006,dworkAlgorithmicFoundationsDifferential2013}. While effective for statistical privacy, differential privacy cannot provide the exact verification guarantees required for financial or regulatory compliance scenarios.

\textbf{Secure Multi-Party Computation (MPC)} allows computation over distributed inputs without a trusted third party, yet typically incurs high latency and communication overheads that are challenging for constrained IoT devices \cite{yaoHowGenerateExchange1986,goldreichHowPlayANY1987,damgardMultipartyComputationSomewhat2012}. The continuous communication requirements make MPC less suitable for the intermittent connectivity patterns common in IoT deployments.

\textbf{Trusted Execution Environments (TEEs)} provide hardware-backed isolation for secure computation, but introduce additional trust assumptions and are vulnerable to side-channel attacks. Furthermore, TEE availability varies significantly across IoT device classes, limiting deployment flexibility.

\textbf{ZK-STARKs} offer transparency and post-quantum security, but generally require larger proof sizes and higher prover costs compared to SNARK systems, making them less suitable for bandwidth-constrained IoT environments.

\subsection{Why zk-SNARKs for IoT Aggregation}

Given our goal of verifiable aggregation under device and bandwidth constraints, zk-SNARKs provide the optimal balance of proof succinctness, verification efficiency, and privacy guarantees. Our empirical evaluation demonstrates that recursive zk-SNARKs (Nova) can achieve constant-size verification while maintaining computational integrity, making them particularly suitable for resource-constrained IoT environments.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion \& Future Work}
\label{chap:conclusion}



\printbibliography

\end{document}


