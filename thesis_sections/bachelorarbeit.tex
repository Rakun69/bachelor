\documentclass[english,bibtotoc,liststotoc,oneside,BCOR=5mm,DIV=12]{scrbook}
\recalctypearea

\usepackage[english]{babel}
\usepackage[T1]{fontenc}
\usepackage{lmodern}
\usepackage{microtype}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{graphicx}
\usepackage{float}
\usepackage{url}
\usepackage{hyperref}
\usepackage[nameinlink]{cleveref}
\usepackage{pgfplots}
\usepackage{tikz}
\usetikzlibrary{positioning,fit,arrows.meta,backgrounds}
\usepackage{adjustbox} % für max width = \linewidth
\usepackage{booktabs}
\usepackage{siunitx}
\pgfplotsset{compat=1.18}
\usepackage{listings, color}
\usepackage{subcaption}
\usepackage[automark]{scrlayer-scrpage}
\setlength{\marginparwidth}{2cm}
\usepackage{todonotes}
\usepackage{comment}
\usepackage{tikz}
\usetikzlibrary{shapes,arrows,positioning,fit,backgrounds,shadows,decorations.pathmorphing,decorations.pathreplacing}
\usetikzlibrary{calc,intersections,through,backgrounds,matrix}
\usetikzlibrary{arrows.meta, calc, positioning, shapes.geometric}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{tabularx}
\usepackage{array}
\newcolumntype{Y}{>{\raggedright\arraybackslash}X}
\usepackage[table]{xcolor}
\usepackage[most]{tcolorbox}
\tcbuselibrary{listings,skins}
% Neutral panel with teal accent for algorithms/notes
\newtcolorbox{algwithnotes}[1][]{enhanced,breakable,sharp corners,boxrule=0.6pt,
  colback=blue!3!white,colframe=black!20,borderline west={2pt}{0pt}{teal!70!black},
  title={#1},fonttitle=\bfseries}

% Listings style for nicer code blocks
\lstdefinestyle{codeblock}{%
  basicstyle=\ttfamily\small,
  breaklines=true,
  columns=fullflexible,
  keepspaces=true,
  showstringspaces=false,
  frame=single,
  framerule=0.5pt,
  backgroundcolor=\color{blue!5!white},
  rulecolor=\color{teal!70!black},
  numbers=left,
  numberstyle=\tiny,
  numbersep=16pt,
  xleftmargin=2.6em,
  framexleftmargin=2.0em
}
\lstset{style=codeblock}

% Theorem-like environments
\newtheorem{definition}{Definition}

\usepackage{booktabs}
\usepackage{csquotes}
\usepackage[backend=biber, style=ieee]{biblatex}
\addbibresource{bib/references.bib}

% Only number and list up to sections (no subsection/subsubsection numbering in ToC or headings)
\setcounter{secnumdepth}{1}
\setcounter{tocdepth}{1}

\clearpairofpagestyles
\chead[Verifiable Data Transformations in IoT Environments – Ramón Felipe Kühne]{Verifiable Data Transformations in IoT Environments – Ramón Felipe Kühne}
% Unified footer for all page styles (plain and scrheadings)
\cfoot[TU Berlin, 2025 \quad | \quad \thepage]{TU Berlin, 2025 \quad | \quad \thepage}
\KOMAoptions{headsepline=.4pt}
\renewcommand*{\chapterpagestyle}{scrheadings}
\pagestyle{scrheadings}

\graphicspath{{./img/}{../data/visualizations/}}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}

\frontmatter
\input{misc/titlepage}
    \thispagestyle{empty}
    \cleardoublepage
    
\input{misc/self-assertion}
    \thispagestyle{empty}
    \cleardoublepage

% Switch to arabic numbering for all following pages
\mainmatter
\pagenumbering{arabic}
\setcounter{page}{1}

\section*{Declaration of Authorship}
I hereby declare that I have written this thesis independently and have not used any sources or aids other than those stated. All passages taken directly or indirectly from the published or unpublished work of others have been identified as such. This thesis has not been submitted in substantially the same form to any other examination board and has not been published.

\clearpage

\section*{Abstract}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section*{Acknowledgements}

\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\tableofcontents
\clearpage
\cleardoublepage
\listoffigures
\clearpage
\listoftables
\clearpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Introduction}
\label{sec:intro}

\section{Motivation}
\label{sec:motivation}
IoT deployments such as smart home sensors, industrial monitors, and environmental sensing networks generate continuous high resolution time series data. To reduce communication and storage demands on resource constrained edge devices, this data is often aggregated in batches, for example via summation or averaging. Conventional aggregation lacks formal guarantees regarding data integrity and privacy \cite{SmartMeterPrivacySurvey2023, AStudyOnPrivacyPreserving2021}. Research has shown that even coarse patterns like hourly energy usage can expose private habits \cite{muellerGewinnungVerhaltensprofilenAm2010}. Aggregation pipelines that rely on unverified local computation are susceptible to tampering or omission, which undermines trust in reported values \cite{bohliPrivacyModelSmart2010aa}. This combination of emerging privacy threats and trust issues highlights the need for cryptographic verification mechanisms in IoT aggregation systems.

Global data production has exploded over the past decade. In 2010 approximately 2 zettabytes of data existed. By 2023 that number reached about 120 zettabytes. In 2024 it rose to approximately 147 zettabytes. Projections expect global data volume to grow further to 181 zettabytes by 2025 \cite{IDCExpect175, HowMuchData}. This dramatic increase magnifies the potential impact of large scale data breaches. In the healthcare sector alone the number of breaches reported to U.S. authorities reached 725 in 2023, exposing over 133 million records \cite{alderDecember2023Healthcare2024}.

The proliferation of IoT devices further accelerates data generation and increases privacy risk. Smart thermostats, smart meters, wearable health trackers, voice assistants, and environmental sensors continuously collect sensor data, often without users’ full awareness. These devices shape daily life and generate intimate behavioral insights.

Because massive volumes of data are generated every moment and breaches are escalating, ensuring the integrity and confidentiality of aggregated data has become critically important. This motivates the development of cryptographic methods that can verify aggregated IoT data without compromising user privacy.

\section{Problem Statement}
\label{sec:problemstatement}
The central problem of this thesis has two main aspects. First, existing aggregation methods do not provide formal integrity guarantees. In practice, users cannot confirm that published aggregates include all raw sensor readings nor detect whether any data were omitted or modified during processing. Second, although zkSNARKs allow confidential proofs of correctness, classical non recursive approaches become increasingly inefficient when used repeatedly for continuous streaming data. The core inefficiency stems from computational complexity, especially during witness generation, which can easily become a bottleneck on IoT hardware with limited resources \cite{ElHajj2024BenchmarkStudy}. In addition, many traditional zkSNARK protocols depend on a trusted setup and do not allow parallel processing, which limits their scalability in IoT use cases.

Recursive zkSNARKs present a promising alternative. They support proof chaining across batches, so that verification cost is amortized rather than repeated. Recent systems such as GENES demonstrate substantial improvements in proving time and verification latency through recursive proof composition. However, these improvements sometimes come with the trade off of larger overall proof sizes \cite{Genes2025EfficientRecursiveSnark}. Likewise, Zecale demonstrates how recursive aggregation can substantially reduce verification overhead while preserving privacy in blockchain contexts \cite{Rondelet2020Zecale}. Despite these theoretical advantages, the deployment of recursive zkSNARKs in constrained, privacy critical IoT environments has not yet been evaluated.

This research therefore targets a gap in current understanding by empirically establishing when recursive zkSNARKs offer a measurable advantage compared to classical zkSNARKs under realistic IoT conditions (hardware limits, privacy objectives, communication constraints). Our benchmarks compare recursive systems to non‑recursive implementations using identical data and report only measured latency, memory, and proof‑size results to produce actionable guidance for real‑world system designers.

\section{Research Questions}

Our research is guided by the following primary questions:

\begin{enumerate}
    \item Under which conditions is the use of recursive SNARKs beneficial?
    \item What added value do recursive SNARKs provide in the context of privacy?
    \item From which data volume or computational complexity onwards are recursive SNARKs more efficient?
    \item Can empirical measurements on realistic IoT setups determine when recursion becomes advantageous?
    \item What are the privacy-performance trade-offs in recursive vs. standard SNARK systems?
\end{enumerate}

\section{Contributions}

This thesis makes the following key contributions:

\begin{enumerate}
    \item \textbf{Nova Implementation}: Complete implementation of Nova recursive SNARKs optimized for IoT data processing
    \item \textbf{Empirical Validation}: Comprehensive resource-constrained IoT evaluation
    \item \textbf{Performance Analysis}: Detailed benchmarking across multiple scenarios using real measurements only
    \item \textbf{Practical Guidelines}: Decision frameworks for choosing appropriate proof systems
\end{enumerate}

\section{Thesis Structure}

\noindent The thesis is organized into eight chapters that map directly to the research questions and the evaluation pipeline:
\begin{enumerate}
    \item \textbf{Introduction} (\cref{sec:intro}): Motivation, problem statement, research questions, contributions, and chapter roadmap.
    \item \textbf{Background} (\cref{sec:background}): Task-relevant overview of IoT aggregation privacy risks and zero-knowledge systems; emphasis on concepts required to interpret the later crossover analysis.
    \item \textbf{Related Work} (\cref{chap:related-work}): Positioning within IoT privacy aggregation and zero-knowledge literature; highlights the gap this thesis addresses; core concepts and trade-offs of recursive vs. non-recursive zk-SNARKs relevant to this study.
    \item \textbf{System Architecture} (\cref{chap:system-architecture}): End-to-end architecture and components; actors; data flow and threat model; how the project is structured and executed.
    \item \textbf{Implementation} (\cref{chap:implementation}): Pipelines, tooling, measurement harness, reproducibility, and limitations.
    \item \textbf{Empirical Results and Analysis} (\cref{chap:empirical-results}): Integrated results covering crossover validation, temporal batching, sensitivity analysis, device-level performance, and practical selection guidelines.
    \item \textbf{Discussion} (\cref{chap:discussion}): Interpretation of findings, decision framework for practitioners, and threats to validity.
    \item \textbf{Conclusion \& Future Work} (\cref{chap:conclusion}): Summary of contributions and directions for future research.
\end{enumerate}

\noindent This structure keeps the narrative focused on the central objective: reporting strictly empirical advantages of recursive SNARKs in IoT settings. Each part either introduces a necessary concept, contributes a component of the methodology, or reports measured results that directly answer the research questions.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Background}
\label{sec:background}
\section{Privacy \& Data Aggregation in IoT}
Resource constrained devices in Internet of Things environments collect and transmit sensor data such as temperature, power usage or motion events. Aggregating this data can reduce communication load and storage overhead, but doing so without cryptographic guarantees can compromise data integrity or privacy. A review by Ali et al \cite{InayatAliPrivacyPreservingDataAggregation2018} shows that traditional data aggregation techniques may expose raw readings and remain vulnerable to inference or tampering, especially in constrained sensor networks. Solutions such as LiPI \cite{GoyalLiPI2022} propose lightweight data masking mechanisms, but they often trade off integrity verification or depend on trusted components. There is limited research on cryptographically verifiable aggregation tailored for resource limited IoT nodes, especially when continuous privacy preservation is required.

\section{Overview of Zero-Knowledge Proofs}
A zero-knowledge proof (ZKP) lets a prover convince a verifier that a statement is true without revealing any additional information beyond its truth \cite{goldwasserKnowledgeComplexityInteractive1985}. ZKPs exist in interactive and non-interactive forms.
zk-SNARKs are non-interactive arguments of knowledge with succinct proofs; in many constructions, proof size and verifier work are sublinear—often effectively constant—in the size of the computation, though they may depend on public input size and typically require a setup \cite{nitulescuZkSnarksAGentleIntroduction2021}. zk-SNARKs have seen prominent deployments, e.g., in Zerocash/Zcash \cite{bensassonZerocashDecentralizedAnonymous2014,hopwoodZcashProtocolSpecification}.
zk-STARKs are transparent (no trusted setup) and hash-based; they scale well and are plausibly post-quantum, but usually incur larger proofs and higher prover costs \cite{ben-sassonScalableZeroKnowledge2019}.
Bulletproofs provide short non-interactive proofs without trusted setup with logarithmic proof size for certain statements (e.g., range proofs); however, verification is generally more expensive than in SNARK systems for large circuits \cite{BulletproofsStanfordApplied}.
Other families (e.g., Sonic, Plonk/Halo variants) explore different trade-offs in universality, transparency, setup, and efficiency \cite{mallerSonicZeroKnowledgeSNARKs2019}.
A recent survey overviews applications and practical frameworks across domains \cite{ASurveyApplicationsZKP2024}.

\section{Verifiable Transformations in IoT Environments}

Verifiable transformations in IoT environments refer to cryptographic computations that process sensor data while maintaining both privacy and computational integrity guarantees. These transformations enable the verification of data processing correctness without revealing individual sensor readings, making them essential for privacy-preserving IoT aggregation systems.

\subsection{Definition and Requirements}

A verifiable transformation in IoT contexts must satisfy three fundamental requirements: (i) \emph{computational integrity}, ensuring that published results represent correct computations over authentic input data; (ii) \emph{privacy preservation}, preventing the disclosure of individual sensor readings beyond what is logically implied by the output; and (iii) \emph{verification efficiency}, enabling efficient proof verification even on resource-constrained devices.

\subsection{Circuit Logic and Cryptographic Components}

The circuit logic for IoT verifiable transformations typically involves several cryptographic components. First, \emph{device signature verification} ensures that each sensor reading originates from an authenticated IoT device using the device's public key. Second, \emph{computational integrity verification} proves that the aggregation function was applied correctly to the verified inputs. The circuit design distinguishes between \emph{public arguments} (device public keys, aggregated results, timestamps) and \emph{private arguments} (individual sensor readings, device private keys, intermediate computation states).

\subsection{General Transformation Types}

Our implementation demonstrates several classes of verifiable transformations applicable to IoT environments:

\begin{itemize}
\item \textbf{Range Validation}: Proving that sensor readings fall within acceptable bounds without revealing individual values
\item \textbf{Statistical Aggregation}: Computing sums, means, medians, or other statistics while maintaining input privacy
\item \textbf{Threshold Compliance}: Verifying that aggregated metrics meet predefined thresholds without exposing individual contributions
\item \textbf{Temporal Analysis}: Proving properties about data collected over time windows while preserving temporal privacy
\end{itemize}

These transformations form the foundation for privacy-preserving IoT data processing, enabling verifiable analytics while protecting individual device privacy.

\subsection*{Why we do not include a non-ZK baseline}
Non-cryptographic pipelines can be faster, but they reveal raw inputs or rely on trust in the computing entity, violating our privacy and integrity requirements. Without zero-knowledge proofs, a verifier cannot simultaneously ensure input confidentiality and computational correctness \cite{goldwasserKnowledgeComplexityInteractive1985,katzIntroductionModernCryptography2007}. Therefore, we compare proof systems (standard vs. recursive zk-SNARKs) rather than including a non-ZK baseline as a candidate solution.

\section{Recursive ZKPs and Aggregation}
Recursive zero knowledge proofs stack or fold multiple proofs into a single succinct result. This enables efficient and scalable verification especially in streaming or multi step computation settings where multiple sub proofs are generated.

\subsection*{Definition of aggregation in this thesis}
We use the term \emph{aggregation} narrowly to denote computations over sets or windows of readings that reduce raw data to concise statistics or validity results (e.g. range validation, sum/mean/median, min/max). In our scope, privacy-preserving aggregation must (i) reveal nothing about individual readings beyond what is logically implied by the output, and (ii) enable verifiers to check correctness without access to raw inputs. These requirements motivate zero-knowledge approaches \cite{goldwasserKnowledgeComplexityInteractive1985,katzIntroductionModernCryptography2007} and connect directly to our circuits and pipeline in \cref{chap:implementation}.

\subsection{Principles and Benefits}
The core idea of recursive ZKPs is to verify a proof inside another proof, thus composing multiple statements into an incrementally verifiable chain. This approach is formalized in theories such as incrementally verifiable computation and proof folding schemes. Nova introduced an efficient folding scheme that absorbs complexity into a relaxed R1CS representation, dramatically reducing per proof cost while maintaining succinct final proofs \cite{NovaFoldingIVC2023}. This makes recursion especially powerful when many steps must be verified sequentially.

\subsection{Frameworks: Halo, Nova, Plonky2}
Halo, introduced by Bowe et al in 2019, pioneered recursive SNARK designs that do not require a trusted setup. It supports cycles of elliptic curves and recursive proof composition transparently \cite{boweRecursiveProofComposition2019}. Nova builds on similar ideas through an efficient folding based proof aggregation strategy and achieves state of the art performance in proof generation and succinctness \cite{NovaFoldingIVC2023, PantheonNovaBenchmark}. Plonky2 is a zk-STARK based system optimized by Polygon Zero for recursive workloads. It uses custom gates and deep arithmetic constraints to enable recursion at scale with high proving speed \cite{Plonky2ZKM2025, AnalysisPlonky2Protocol, IntroducingPlonky2, MayaZKBlogAggregationSummary}. All three systems allow continual chaining of proofs and compression into a single final proof, reducing verification overhead in multi step or streaming use cases.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Related Work}
\label{chap:related-work}

\section{IoT Privacy and Data Aggregation}

The overlap between IoT privacy preservation and data aggregation has been extensively studied. Traditional approaches to IoT data aggregation often sacrifice privacy for efficiency, creating vulnerabilities in smart home and industrial deployments \cite{SmartMeterPrivacySurvey2023, AStudyOnPrivacyPreserving2021}.

\subsection{Privacy-Preserving IoT Aggregation}

Early work by Ali et al. demonstrated that conventional aggregation techniques expose raw sensor readings to inference attacks \cite{InayatAliPrivacyPreservingDataAggregation2018}. Solutions such as LiPI propose lightweight obfuscation mechanisms but often trade off integrity verification or depend on trusted components \cite{GoyalLiPI2022}.

Recent advances in differential privacy for IoT have shown promise but struggle with the continuous, high-frequency nature of sensor data. The challenge lies in balancing privacy preservation with the computational and energy constraints of IoT devices. Prior work rarely offers end-to-end, verifiable aggregation with measured crossover points under resource constraints; our study fills this empirical gap by reporting only measured results and explicit crossover regimes.

\subsection*{Critical positioning}
Compared to prior surveys and systems, our contribution is explicitly empirical and hardware-aware: (i) we benchmark standard vs. recursive zk-SNARKs on identical logic and data under matched resource limits enforced via Docker (CPU/RAM constraints), and (ii) we report time/size crossovers under steady-state operation. Many prior works emphasize protocol design or transparency properties (e.g., STARKs) without quantifying when recursion is advantageous under constrained compute and memory. Our results provide that missing, practical boundary.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Recursive vs. Non-Recursive zk-SNARKs in Resource-Constrained Environments}
\label{sec:zk-snark-comparison}

\subsection{Fundamentals: Difference Between Recursive and Non-Recursive zk-SNARKs}

zk-SNARKs (Zero-Knowledge Succinct Non-Interactive Arguments of Knowledge) allow one to prove the correctness of a computation using a short cryptographic proof without revealing the underlying data. A non-recursive zk-SNARK refers to a single proof for a specific computation or statement. In contrast, recursive zk-SNARKs allow multiple proofs or computation steps to be composed into each other. In recursion, the output of one zk-SNARK is used as part of the input for the next, resulting in a single final proof that attests to the correctness of all intermediate computations \cite{innovationBlockchainScalabilityGuide}. This is also known as incrementally verifiable computation (IVC): the prover produces a proof for each computation step that confirms both the correctness of that step and that the previous step was correctly verified \cite{bellachiaVerifBFLLeveragingZkSNARKs2025}. Through this composition, iterative or sequential computations can be securely chained.

A well-known example of recursive zk-SNARKs is Nova, which is based on a folding scheme. Nova folds a long computation into an ongoing recursive proof and only generates the final zk-SNARK at the end \cite{ElHajj2024BenchmarkStudy}. As a result, the expensive zk-SNARK generation occurs only once—regardless of how many steps were involved in the computation. Systems such as Halo or Nova have demonstrated that recursive zk-SNARKs can be built without a trusted setup, making them suitable for real-world applications \cite{ElHajj2024BenchmarkStudy}.

\subsection{Efficiency, Computation Cost, and Latency}

The primary efficiency difference lies in the trade-off between proof generation and verification. In non-recursive zk-SNARKs, generating a single proof is expensive, but verifying that proof is very fast (often milliseconds). However, if multiple zk-SNARKs must be verified (e.g., many individual proofs), the overall verification time scales linearly. Recursive zk-SNARKs aim to drastically reduce this verification overhead by aggregating all claims into a single proof \cite{innovationBlockchainScalabilityGuide}. Thus, the final verification time remains essentially constant, regardless of the number of individual steps or proofs involved.

On the proving side, recursive SNARKs introduce some overhead, since each new proof must verify the previous one, increasing the number of constraints. In traditional constructions (e.g., Groth16), verifying a SNARK inside a SNARK was costly. Modern systems like Nova optimize this by delaying the expensive zk-SNARK compression to the end \cite{ElHajj2024BenchmarkStudy}. Nova works in two stages: it first builds an ongoing recursive proof and then applies a final zk-SNARK compression. This final step incurs a fixed cost, regardless of how many steps were folded in. Hence, the final verification time remains constant, while the proof generation time increases roughly linearly with the number of steps. Latency may increase moderately, since the system waits until the end to compress the accumulated proofs.

Proof size is another major advantage. While a typical Groth16 proof is constant in size, producing many individual proofs results in linear growth in storage or transmission. Recursive SNARKs produce one final compact proof whose size is largely independent of the number of inputs \cite{innovationBlockchainScalabilityGuide}.

\subsection{Scalability}
Recursive zk-SNARKs are most beneficial when dealing with large-scale computations or proof aggregation. For small or one-time computations, a single non-recursive proof is often more efficient, as the recursive overhead may not be justified.

Empirical studies indicate that even at modest batch sizes (a few dozen proofs), recursion can become advantageous. For example, in a decentralized IoT setting, Nova required only \textasciitilde3.6 seconds to aggregate and verify 10 digital signatures, whereas a non-recursive method using Risc0 took \textasciitilde369 seconds—over 100$\times$ slower \cite{bojicburgosDecentralizedIoTData2024}. The gap grows with more inputs. Another study showed that Nova could verify 100 signatures in 7.1 seconds, whereas a previous method based on homomorphic encryption and ECDSA took over 50 seconds to verify just 64 signatures \cite{bojicburgosDecentralizedIoTData2024}. These results suggest that at batch sizes of a few dozen, recursive approaches can already be significantly more efficient.

Moreover, recursion reduces distributed verification overhead. Without recursion, each verifier must check all proofs. With recursion, only a single final proof needs to be verified. This makes the per-claim verification time negligible, since a constant cost is amortized over many claims \cite{bojicburgosDecentralizedIoTData2024}. The load is shifted from weak verifiers (e.g., IoT devices or smart contracts) to a single strong prover.

\subsection{Use in IoT and Smart-Home Scenarios}

IoT and smart-home environments impose strict constraints: sensors and embedded devices often have limited processing power, memory, and energy. zk-SNARK generation is typically too expensive to perform locally \cite{bojicburgosDecentralizedIoTData2024}. Even verification can overwhelm constrained devices. Therefore, many architectures follow a layered model with edge servers.

In this setup, IoT devices only collect and sign data. They then forward it to a nearby edge aggregator, which performs proof generation and aggregation \cite{bojicburgosDecentralizedIoTData2024}. Only the final proof or its hash is sent to a blockchain or central verifier. This eliminates the need for IoT devices to generate or verify SNARKs, saving energy and bandwidth.

Recursive zk-SNARKs are ideal for such scenarios, as they can aggregate continuous sensor streams into an ongoing proof. For instance, Nova has been used to aggregate and verify 100 sensor signatures into a single proof suitable for on-chain verification \cite{bojicburgosDecentralizedIoTData2024}. Verifying this proof took only \textasciitilde0.06\,s per signature (i.e., \textasciitilde6\,s total), even for low-powered verifiers.

Beyond signature verification, recursive SNARKs can prove compliance with rules over long periods, such as “no sensor exceeded a threshold for the past hour.” This streaming proof model allows incremental updates and compact final validation, ideal for constrained environments \cite{ElHajj2024BenchmarkStudy}.

Studies have even demonstrated recursive zk-SNARKs in advanced tasks like federated learning: each local training round and the global aggregation step are provably verified using Nova. In one setup, the global model proof took \textasciitilde81 seconds to generate and \textasciitilde0.6 seconds to verify \cite{bellachiaVerifBFLLeveragingZkSNARKs2025}. This shows that the cost is mostly on the proving side, which can be offloaded to strong devices.

\subsection{Summary and Implications for Architecture}
Recursive zk-SNARKs offer compelling benefits for scaling zero-knowledge applications in IoT scenarios. They enable aggregation of multiple computations or data streams into a single compact proof, which reduces memory, bandwidth, and verification cost—key concerns in resource‑constrained environments. Our system architecture (\cref{chap:system-architecture}) therefore places proving at an edge aggregator, defines batching policies that drive into empirically observed crossover regimes, and adopts metrics (proof time, verification time, proof size, and device load) that operationalize these trade‑offs. The following chapter translates these implications into a concrete architecture and methodology and specifies the evaluation setup used to validate them in practice.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{System Architecture}
\label{chap:system-architecture}

\begin{figure}[H]
\centering
\begin{adjustbox}{max width=\linewidth,center}
\begin{tikzpicture}[
  font=\small,
  x=1cm,y=1cm,
  box/.style={draw, rounded corners=2pt, align=center, minimum width=4.0cm, minimum height=1.1cm, fill=blue!3},
  group/.style={draw, dashed, rounded corners=3pt, inner sep=6pt},
  arrow/.style={-Latex, thick},
  lab/.style={font=\footnotesize, fill=white, inner sep=1pt, outer sep=2pt, text depth=0pt}
]

\node[box] (dev1) at (0,0.8) {IoT device};
\node[box, below=2mm of dev1] (dev2) {IoT device};
\node[box, below=2mm of dev2] (dev3) {IoT device};
\node[group, fit=(dev1)(dev3), label=above:{Device domain}] (devdom) {};

\node[box, right=3.4cm of dev2] (ingest) {Data collection \& batching};
\node[box, below=4mm of ingest, minimum width=4.6cm] (prover) {Proof generator};
\node[group, fit=(ingest)(prover), label=above:{Edge domain}] (edgedom) {};

\node[box, right=3.1cm of prover, minimum width=4.2cm] (verifier) {Verifier / Consumer};
\node[group, fit=(verifier), label=above:{Consumer domain}] (condom) {};

\node[fit=(devdom)(edgedom), inner sep=16pt] (dockfit) {};
\begin{pgfonlayer}{background}
  \draw[dashed, very thick, rounded corners=3pt] (dockfit.north west) rectangle (dockfit.south east);
\end{pgfonlayer}
\node[lab, above=2mm of dockfit.north] {resource-limited Docker container};

\draw[arrow] (devdom.east) -- (ingest.west) node[lab, above, pos=0.5] {readings};
\draw[arrow] (prover.east) -- (verifier.west) node[lab, above, pos=0.5] {aggregate + proof};

\end{tikzpicture}
\end{adjustbox}
\caption{System Architecture}
\label{fig:system-overview}
\end{figure}

\paragraph{Explanation}
The figure shows our systme architecture for comparing standard and recursive zk-SNARKs in IoT environments. The system processes simulated IoT sensor data in configurable batches as input to proof generation. Two proving modes are evaluated. In the standard mode, Groth16 with a circuit-specific trusted setup is used and consumers verify one proof per individual reading (or per sub-aggregate, depending on the circuit). In the recursive mode, Nova folds the computation across a batch; if a final Groth16 compression is applied, the consumer verifies a single proof for the entire batch and that compression relies on a trusted setup for the compression circuit. No dedicated key-management service is modeled because this is a benchmarking framework with simulated data; all cryptographic parameters are generated locally using standard ZoKrates setup flows \cite{TrustedSetupZoKrates}. To approximate real-world constraints, the entire system runs inside a resource-limited Docker container, which emulates the compute and memory limits typical of IoT devices, while consumers remain external.

\paragraph{Component terminology (Figure~\ref{fig:system-overview}).}
\begin{itemize}
  \item \textbf{Device domain}: Produces and forwards IoT sensor readings to the edge for processing.
  \item \textbf{Edge domain}: receives readings, orders them, groups inputs into configurable batches, and generates zk-proofs (Groth16 or Nova with final Groth16 compression)
  \item \textbf{Consumer domain}: Receives aggregates and verifies either multiple Groth16 proofs (standard) or a single final Groth16 proof (Nova compression).
  \item \textbf{Execution boundary}: The dashed box represents a resource-limited Docker container used to emulate IoT-like compute and memory constraints.
\end{itemize}

This chapter establishes the evaluation framework used to compare standard and recursive zk-SNARKs in IoT environments and defines the system components at a technology-agnostic level. The architecture follows an edge-centric pattern \cite{shiEdgeComputingVision2016}.

The architecture in Figure~\ref{fig:system-overview} is designed to compare a standard zk-SNARK pipeline (Groth16) with a recursive pipeline (Nova) under conditions that are close to practice but still fully controllable. At the left, a device domain produces streams of simulated IoT readings that are handed over to the edge. The edge receives the readings, rounds floating-point values to integers where needed for zk-SNARK compatibility, and forms configurable batches of readings that serve as inputs to proof generation. Two proof modes are evaluated on the same data: a standard mode based on Groth16 with a circuit-specific trusted setup, where consumers verify one proof per individual reading, and a recursive mode based on Nova that folds the computation across configurable batches. The recursive pipeline uses Nova folding followed by Groth16 compression, yielding one succinct proof for the entire batch that the consumer verifies once. Because this is a benchmarking framework with simulated data, no operational key management service is modeled; proving and verification parameters are generated locally using standard ZoKrates trusted setup flows \cite{kothapalli_nova_2022,NovaFoldingIVC2023,TrustedSetupZoKrates}. Transport security and device authentication are not part of this chapter; data may flow in plaintext inside the controlled container, since the focus is on proving and verification costs. In a deployment, confidentiality and authenticity in transit would be provided separately (e.g., authenticated encryption and device signatures).

The smart home scenario is chosen deliberately as the motivating use case. It offers a realistic mix of heterogeneous sensors such as temperature, motion, light, and energy that emit frequent, low-payload readings and need aggregation for dashboards, automation rules, and billing analytics. This setting is representative of edge-centric processing, and typical homes already host a hub or gateway that runs ingestion and computation on the same device. It also captures the two tensions we want to study: privacy, where consumers should learn only aggregates and not device-level values, and tight resource budgets on the processing node. Other candidate domains such as industrial IoT or vehicular telemetry often require specialized hardware and high-throughput networking or introduce strict control loops. Smart homes provide a neutral middle ground with realistic variability in devices and rates, meaningful privacy at the individual level, and a balance between latency and amortization of prover costs. The results therefore translate to similar small-to-medium edge deployments while keeping experiments reproducible.

All experiments run inside a resource-limited Docker container that emulates the compute and memory limits of IoT devices. This execution boundary, shown as the dashed box, contains devices and the edge to keep the data path short and measurable, while consumers remain external to reflect the common pattern where verification and analytics run off device. For each configuration we report prover time, verifier time, proof size, and the resident set size of the edge process, and we summarize results using medians over repeated runs. Zero-knowledge protects inputs from consumers by design. The chapter therefore quantifies the cost and scaling behavior of Groth16 and Nova under bounded resources, while deliberately abstracting from networking, transport security, device identity, and key rotation to isolate the proving pipeline.

\section{Data Flow and Processing Pipeline}
\label{sec:data-flow}

The data processing pipeline differs significantly between standard and recursive zk-SNARK approaches, reflecting their fundamental architectural differences and performance characteristics.

\subsection{Standard SNARK Pipeline}
The standard zk-SNARK approach processes simulated IoT readings individually, following a sequential workflow that emphasizes granular verification capabilities. The process begins when the edge device receives data from the IoT devices. For each individual reading, a separate zk-SNARK proof is generated that demonstrates correct range validation according to predefined circuit constraints using standard ZoKrates trusted setups. These individual proofs are then collected and transmitted to consumers, who must verify each proof separately to validate the entire dataset. This approach ensures that each sensor reading is individually verifiable, providing fine-grained integrity guarantees. However, the verification process requires linear time proportional to the number of readings, creating scalability challenges as the number of readings increases.

\subsection{Recursive SNARK Pipeline}
The Nova recursive approach processes Iot readings in batches, employing a fundamentally different strategy that optimizes for large-scale aggregation scenarios. As in the standard zkSNARK pipeline, the process here also begins when the edge receives sensor readings from the IoT devices. The processing diverges significantly during step preparation, where readings are systematically grouped into configurable steps, with zero-padding applied as necessary to ensure consistent step sizes. This batching strategy enables Nova to fold multiple steps into a single ongoing proof through its efficient folding mechanism, dramatically reducing the computational overhead associated with individual proof generation. The recursive proof generation process accumulates computational claims across multiple steps, creating an incrementally verifiable computation chain. A final zk-SNARK compression stage transforms this accumulated proof into a single succinct proof that encapsulates the correctness of all processing steps using standard ZoKrates trusted setups. The verification process requires consumers to verify only one final proof regardless of input size.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Implementation}
\label{chap:implementation}
\section{Environment and Hardware Profile}
\label{sec:env-hw}

We executed all experiments under a resource-constrained profile intended to simulate realistic IoT edge environments. 
Specifically, we used Docker containers with enforced limits on CPU, memory, and swap space to approximate the hardware characteristics of IoT-devices, such as Raspberry Pi's.

\begin{itemize}
  \item \textbf{CPU}: fixed 0.5 logical core
  \item \textbf{RAM}: fixed 1\,GB
\end{itemize}

These settings are chosen based on typical Raspberry Pi-class device specifications, which often provide ~1-4 GB RAM and single-to-quad-core CPUs in edge deployments. For example, Gupta \& Nahrstedt \cite{guptaPerformanceCharacterizationContainers2025} empirically evaluate similar IoT devices and show that Docker containers on hardware with ~1 GB RAM suffer measurable overheads in latency and I/O under constrained CPU/RAM settings.\\

\noindent Host platform (for emulation):
\begin{table}[H]
  \centering
  \begin{tabular}{ll}
    \hline
    Component & Specification \\
    \hline
    CPU & AMD Ryzen 7 7800X3D (8 cores, 16 threads; base \SI{4.2}{GHz}) \\
    RAM & \SI{32}{GB} DDR5 @ \SI{6000}{MT/s} (2\,\texttimes{} DIMM) \\
    GPU & NVIDIA GeForce RTX 4070 SUPER (12\,GB VRAM) \\
    Virtualization & Windows 11 + WSL2 (Ubuntu kernel 6.6.87.2) \\
    \hline
  \end{tabular}
  \caption{Host platform used to simulate IoT-like environments under resource constraints via Docker/cgroups.}
\end{table}

\subsection{System overview and measurement harness}
Our harness executes the \emph{same} aggregation logic twice per reading size $N$: once with a baseline zk-SNARK (``Standard'') and once with Nova's Incrementally Verifiable Computation (IVC) plus compression (``Nova''), using identical inputs and scripted CLI parameters (\texttt{--mode}, \texttt{--warmup-runs}, \texttt{--repetitions}). The ZoKrates toolchain provides both the baseline pipeline (\texttt{compile} $\rightarrow$ \texttt{setup} $\rightarrow$ \texttt{compute-witness} $\rightarrow$ \texttt{generate-proof} $\rightarrow$ \texttt{verify}) and an experimental Nova backend (\texttt{nova prove} $\rightarrow$ \texttt{nova compress} $\rightarrow$ \texttt{nova verify}) \cite{ExperimentalZoKrates}. Nova realizes recursion via a folding scheme for IVC, yielding verifier time and proof size that are (to first order) independent of recursion depth \cite{kothapalli_nova_2022}.

\paragraph{Data path and outputs.}
For each $N$, we load a window of IoT readings, run the Standard and the Nova pipeline, and record \emph{prove/compress/verify/total} times and proof sizes. Results are persisted as JSON/CSV for post-processing and plots.

\subsection{Cold vs.\ warm execution}
\label{subsec:cold-warm}
We report two execution regimes to bracket realistic deployments:
\begin{itemize}
  \item \textbf{Cold mode:} fresh, isolated workspaces per run; intermediate artifacts removed; no pre-touching. This approximates first-use or infrequent activation when OS page cache and library state are cold.
  \item \textbf{Warm mode:} artifact reuse across runs; optional pre-touch of static files (R1CS, parameters) to promote page-cache residency. This approximates steady-state services.
\end{itemize}
On Linux, repeated file accesses are typically served from the kernel page cache once pages are resident in RAM; subsequent runs can thus avoid disk I/O and appear markedly faster even with identical code and inputs \cite{ConceptsOverviewLinux}. Beyond file caching, additional warmup phenomena (dynamic linking, allocator state, branch predictors, and—in managed runtimes—JIT compilation) can shift early iterations away from steady state. The benchmarking literature cautions that steady state is neither guaranteed nor trivial to detect; discarding initial iterations and using multiple repetitions is recommended over assuming convergence from a single run \cite{barrettWarmupBlowsHotAndCold,trainiEffectiveAssessmentSteady2022}. Accordingly, our harness performs \emph{warm-up runs} that are \emph{excluded} from aggregates and then executes $r$ repetitions per $N$.

\subsection{Pipelines and metrics}
\paragraph{Standard (ZoKrates).}
We compile the aggregation circuit, run setup once, compute witnesses per instance, generate a Groth16 proof, and verify. We record \emph{prove time}, \emph{verify time}, \emph{total time}, and \emph{proof size} (KB).

\paragraph{Nova (IVC + compression).}
We execute \texttt{nova prove} over $N$ steps of the same relation to build the IVC, then \texttt{compress} to a succinct proof and \texttt{verify} the compressed proof. We record \emph{IVC time} (reported as \emph{prove}), \emph{compress time}, \emph{verify time}, \emph{total time}, \emph{proof size}, and (optionally) \emph{folding steps}. Nova’s folding amortizes many instances and makes verifier cost largely $N$-independent \cite{kothapalli_nova_2022}.

\paragraph{Efficiency ratios and crossovers.}
Per $N$ we compute $\text{Eff}_t=T_{\text{std}}/T_{\text{nova}}$ and $\text{Eff}_s=S_{\text{std}}/S_{\text{nova}}$; the \emph{time crossover} is the smallest $N$ with $\text{Eff}_t>1$, the \emph{size crossover} analogously for $\text{Eff}_s>1$. Reporting both is essential because recursive systems may win in verifier cost/size before (or after) they dominate in total time.

\subsection{Controlling sources of variance}
We mitigate common pitfalls: (i) \emph{cache effects} via explicit cold/warm protocols and discarded warm-ups; (ii) \emph{artifact reuse} by isolating Nova workspaces in cold mode; (iii) \emph{non-determinism} via repetitions and median/dispersion reporting; (iv) \emph{configuration drift} via scripted builds and pinned tool versions. These practices align with artifact-evaluation guidance emphasizing functional artifacts, reproducibility, and steady-state assessment \cite{ArtifactReviewBadging}.

\subsection{Environment and constraints}
We emulate resource-constrained edge settings with container-level limits (CPU shares/cores, RAM, swap), stressing prover memory/IO. This matches deployments where proving runs on an edge aggregator, while verifiers (e.g., smart contracts or weak devices) benefit from Nova’s small verification cost \cite{chaliasosAnalyzingBenchmarkingZKRollups2024}. Hardware/software versions and limits are logged with each run.

\subsection{Threats to validity}
\textbf{Internal.} Cold/warm deltas depend on the storage stack and kernel; compression/verification can stay IO-sensitive under cold conditions. We mitigate by workspace isolation, discarded warm-ups, and repeated runs.
\textbf{External.} Results hold for our circuits, limits, and ZoKrates/Nova versions; other relations/backends may shift break-even points (e.g., PLONK-family folding schemes) \cite{varkFoldingCustomGates2024}.
\textbf{Construct.} Following benchmarking best practice, we report both startup/cold and steady/warm behavior rather than assuming steady state \cite{barrettWarmupBlowsHotAndCold,trainiEffectiveAssessmentSteady2022}.

\subsection{Why Nova here}
We center Nova due to its efficient recursion overhead and near-constant verifier cost \cite{kothapalli_nova_2022}, and because ZoKrates exposes an end-to-end path for both baseline and recursive pipelines \cite{ExperimentalZoKrates}. Alternatives (Darlin/Halo-style recursion, PLONK-folding variants, STARKs) offer different trust/transparency and prover-cost trade-offs; a multi-family comparison is orthogonal to our empirical question and left for future work \cite{habockDarlinRecursiveProofs2021,varkFoldingCustomGates2024}.



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Requirements (load once in the preamble):
% \usepackage{graphicx}
% \usepackage{booktabs}
% \usepackage{siunitx}
% \usepackage{hyperref}
% \usepackage{caption}
% \sisetup{round-mode=places,round-precision=2,detect-weight=true,detect-inline-weight=math}

\chapter{Results and Analysis}
\label{chap:empirical-results}

This chapter presents the empirical evaluation of Standard zk-SNARKs versus recursive zk-SNARKs for IoT data aggregation. The analysis reveals significant performance differences between the two approaches.


\section{Performance Results}
\label{sec:performance-results}

This section presents the empirical evaluation results comparing Standard zk-SNARKs versus Nova Recursive zk-SNARKs under different execution conditions. The analysis reveals critical crossover points and performance characteristics that inform practical deployment decisions.

\subsection{Cold Start vs Warm Start Analysis}

Our evaluation distinguishes between cold start and warm start execution conditions, as these significantly impact the performance characteristics of both proof systems.

\subsubsection{Cold Start Results (md\_cold\_2\_3\_nr8)}

Table \ref{tab:cold-performance} shows the performance results under cold start conditions, where each run begins with fresh, isolated workspaces and no pre-cached artifacts.

\begin{table}[H]
\centering
\small
\begin{tabularx}{\textwidth}{@{}lXXXXXX@{}}
\toprule
\textbf{Readings} & \textbf{Std (s)} & \textbf{Std Size (KB)} & \textbf{Nova (s)} & \textbf{Nova Size (KB)} & \textbf{Ratio} & \textbf{Winner} \\
\midrule
100 & 3.79 & 83.3 & 11.43 & 69.2 & 0.33\texttimes{} & Standard \\
200 & 6.70 & 166.6 & 13.91 & 69.2 & 0.48\texttimes{} & Standard \\
300 & 11.37 & 249.9 & 15.33 & 69.2 & 0.74\texttimes{} & Standard \\
400 & 12.66 & 333.2 & 19.48 & 69.1 & 0.65\texttimes{} & Standard \\
500 & 18.89 & 416.5 & 19.26 & 69.1 & 0.98\texttimes{} & Standard \\
600 & 21.07 & 499.8 & 22.54 & 69.1 & 0.93\texttimes{} & Standard \\
700 & 25.57 & 583.1 & 24.07 & 69.2 & 1.06\texttimes{} & \textbf{Nova} \\
800 & 27.75 & 666.4 & 27.33 & 69.2 & 1.02\texttimes{} & Nova \\
900 & 31.53 & 749.7 & 28.83 & 69.2 & 1.09\texttimes{} & Nova \\
1000 & 35.31 & 833.0 & 31.08 & 69.1 & 1.14\texttimes{} & Nova \\
\bottomrule
\end{tabularx}
\caption{Performance comparison under cold start conditions (Docker: 0.5 CPU, 1GB RAM)}
\label{tab:cold-performance}
\end{table}

Under cold start conditions, the crossover point occurs at 700 readings, where Nova begins to outperform Standard SNARKs. This represents a significant threshold that reflects Nova's setup overhead under resource-constrained conditions.

\subsubsection{Warm Start Results (md\_warm\_2\_3\_nr7)}

Table \ref{tab:warm-performance} presents the performance results under warm start conditions, where artifacts are reused and pre-cached for optimal performance.

\begin{table}[H]
\centering
\small
\begin{tabularx}{\textwidth}{@{}lXXXXXX@{}}
\toprule
\textbf{Readings} & \textbf{Std (s)} & \textbf{Std Size (KB)} & \textbf{Nova (s)} & \textbf{Nova Size (KB)} & \textbf{Ratio} & \textbf{Winner} \\
\midrule
100 & 3.49 & 83.3 & 11.65 & 69.2 & 0.30\texttimes{} & Standard \\
200 & 6.99 & 166.6 & 13.78 & 69.2 & 0.51\texttimes{} & Standard \\
300 & 10.84 & 249.9 & 15.56 & 69.2 & 0.70\texttimes{} & Standard \\
400 & 15.01 & 333.2 & 17.10 & 69.1 & 0.88\texttimes{} & Standard \\
500 & 17.25 & 416.5 & 20.95 & 69.1 & 0.82\texttimes{} & Standard \\
600 & 20.93 & 499.8 & 22.49 & 69.1 & 0.93\texttimes{} & Standard \\
700 & 24.72 & 583.1 & 24.98 & 69.2 & 0.99\texttimes{} & Standard \\
800 & 27.81 & 666.4 & 27.43 & 69.2 & 1.01\texttimes{} & \textbf{Nova} \\
900 & 31.39 & 749.7 & 28.90 & 69.2 & 1.09\texttimes{} & Nova \\
1000 & 35.43 & 833.0 & 31.29 & 69.1 & 1.13\texttimes{} & Nova \\
\bottomrule
\end{tabularx}
\caption{Performance comparison under warm start conditions (Docker: 0.5 CPU, 1GB RAM)}
\label{tab:warm-performance}
\end{table}

Warm start conditions shift the crossover point to 800 readings, demonstrating that Nova benefits significantly from pre-cached artifacts and optimized execution paths.

\subsection{Resource-Constrained vs Full Resources Analysis}

\subsubsection{Resource-Constrained Results (od\_cold\_2\_5)}

Table \ref{tab:resource-constrained} shows performance under severe resource constraints, simulating typical IoT edge device limitations.

\begin{table}[H]
\centering
\small
\begin{tabularx}{\textwidth}{@{}lXXXXXX@{}}
\toprule
\textbf{Readings} & \textbf{Std (s)} & \textbf{Std Size (KB)} & \textbf{Nova (s)} & \textbf{Nova Size (KB)} & \textbf{Ratio} & \textbf{Winner} \\
\midrule
10 & 1.72 & 8.3 & 8.98 & 69.2 & 0.19\texttimes{} & Standard \\
25 & 4.33 & 20.8 & 8.89 & 69.1 & 0.49\texttimes{} & Standard \\
50 & 7.21 & 41.7 & 10.30 & 69.1 & 0.70\texttimes{} & Standard \\
75 & 11.93 & 62.5 & 10.03 & 69.1 & 1.19\texttimes{} & \textbf{Nova} \\
100 & 16.28 & 83.3 & 10.54 & 69.2 & 1.54\texttimes{} & Nova \\
150 & 23.95 & 125.0 & 11.72 & 69.2 & 2.04\texttimes{} & Nova \\
200 & 31.91 & 166.6 & 12.94 & 69.2 & 2.47\texttimes{} & Nova \\
\bottomrule
\end{tabularx}
\caption{Performance comparison under resource-constrained conditions (Docker: 0.5 CPU, 1GB RAM)}
\label{tab:resource-constrained}
\end{table}

Under resource-constrained conditions, the crossover point occurs at 75 readings, demonstrating that Nova can be advantageous even with limited computational resources.

\subsubsection{Full Resources Results (od\_warm\_1\_5)}

Table \ref{tab:full-resources} presents performance with full system resources available, showing optimal execution conditions.

\begin{table}[H]
\centering
\small
\begin{tabularx}{\textwidth}{@{}lXXXXXX@{}}
\toprule
\textbf{Readings} & \textbf{Std (s)} & \textbf{Std Size (KB)} & \textbf{Nova (s)} & \textbf{Nova Size (KB)} & \textbf{Ratio} & \textbf{Winner} \\
\midrule
50 & 8.53 & 41.7 & 8.95 & 69.1 & 0.95\texttimes{} & Standard \\
60 & 9.83 & 50.0 & 9.64 & 69.1 & 1.02\texttimes{} & \textbf{Nova} \\
70 & 11.55 & 58.3 & 10.02 & 69.1 & 1.15\texttimes{} & Nova \\
80 & 13.35 & 66.6 & 10.15 & 69.1 & 1.31\texttimes{} & Nova \\
90 & 14.75 & 75.0 & 10.45 & 69.1 & 1.41\texttimes{} & Nova \\
100 & 16.31 & 83.3 & 11.23 & 69.2 & 1.45\texttimes{} & Nova \\
125 & 21.58 & 104.1 & 10.86 & 69.1 & 1.99\texttimes{} & Nova \\
150 & 25.87 & 125.0 & 10.52 & 69.2 & 2.46\texttimes{} & Nova \\
\bottomrule
\end{tabularx}
\caption{Performance comparison with full system resources (no Docker limitations)}
\label{tab:full-resources}
\end{table}

With full resources, the crossover point occurs at 60 readings, showing that Nova's advantages become apparent earlier under optimal conditions.

\subsection{Crossover Point Analysis}

The empirical results reveal distinct crossover points depending on execution conditions:

\begin{itemize}
\item \textbf{Cold Start}: Crossover at 700 readings
\item \textbf{Warm Start}: Crossover at 800 readings  
\item \textbf{Resource-Constrained}: Crossover at 75 readings
\item \textbf{Full Resources}: Crossover at 60 readings
\end{itemize}

This analysis demonstrates that Nova's performance advantages are highly dependent on execution context, with resource constraints and execution state significantly influencing the crossover threshold.

\subsection{Visual Performance Analysis}

The following figures provide comprehensive visual analysis of the performance characteristics across different execution conditions.

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{md_cold_2_3_nr8/real_crossover_overview.png}
\caption{Performance comparison visualization for cold start conditions (md\_cold\_2\_3\_nr8). The plot shows the crossover point at 700 readings where Nova begins to outperform Standard SNARKs.}
\label{fig:cold-visualization}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{md_warm_2_3_nr7/real_crossover_overview.png}
\caption{Performance comparison visualization for warm start conditions (md\_warm\_2\_3\_nr7). The plot demonstrates the shifted crossover point at 800 readings under optimized execution conditions.}
\label{fig:warm-visualization}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{od_cold_2_5/od_cold_2_5.png}
\caption{Performance comparison visualization for resource-constrained conditions (od\_cold\_2\_5). The plot shows the early crossover point at 75 readings under severe resource limitations.}
\label{fig:resource-constrained-visualization}
\end{figure}

\begin{figure}[H]
\centering
\includegraphics[width=0.8\textwidth]{od_warm_1_5/od_warm_1_5.png}
\caption{Performance comparison visualization for full resources conditions (od\_warm\_1\_5). The plot demonstrates the optimal crossover point at 60 readings with full system resources available.}
\label{fig:full-resources-visualization}
\end{figure}


\subsection{Detailed Performance Analysis}

\subsubsection{Proof Size Characteristics}

The analysis reveals fundamental differences in proof size characteristics between Standard and Nova SNARKs:

\begin{itemize}
\item \textbf{Standard SNARKs}: Linear growth in proof size (8.3 KB per reading)
\item \textbf{Nova Recursive}: Constant proof size (~69.1 KB regardless of batch size)
\end{itemize}

This constant proof size characteristic of Nova becomes increasingly advantageous as configurable batch sizes grow, providing significant bandwidth savings for large-scale IoT deployments.

\subsubsection{Performance Scaling Patterns}

The empirical results demonstrate distinct scaling patterns:

\begin{itemize}
\item \textbf{Standard SNARKs}: Linear time complexity O(n) with consistent per-reading overhead
\item \textbf{Nova Recursive}: Near-constant time complexity O(1) after initial setup overhead
\end{itemize}

These scaling characteristics explain the observed crossover points and provide guidance for deployment decisions.

\subsubsection{Resource Impact Analysis}

The comparison between resource-constrained and full-resource environments reveals:

\begin{itemize}
\item \textbf{Resource Constraints}: Shift crossover points significantly (75 vs 60 readings)
\item \textbf{Execution State}: Cold vs warm start affects crossover by 100 readings (700 vs 800)
\item \textbf{Memory Pressure}: Nova's constant memory usage becomes advantageous under constraints
\end{itemize}

\subsection{Practical Deployment Guidelines}

Based on the empirical analysis, the following deployment guidelines emerge:

\subsubsection{Use Standard SNARKs when:}
\begin{itemize}
\item Configurable batch sizes are below the crossover threshold for the specific deployment context
\item Real-time processing requirements demand minimal latency
\item Individual proof verification is required
\item Memory constraints are not a primary concern
\end{itemize}

\subsubsection{Use Nova Recursive SNARKs when:}
\begin{itemize}
\item Configurable batch sizes exceed the crossover threshold (60-800 readings depending on context)
\item Bandwidth efficiency is critical (constant proof size advantage)
\item Memory-constrained environments require predictable resource usage
\item Long-term steady-state operation is expected (warm start conditions)
\end{itemize}

\subsection{Threats to Validity}

Several limitations must be considered when interpreting these results:

\begin{itemize}
\item \textbf{Circuit Specificity}: Results are specific to the implemented aggregation circuits
\item \textbf{Hardware Dependencies}: Performance characteristics may vary across different hardware platforms
\item \textbf{Software Versions}: Results depend on specific versions of ZoKrates and Nova implementations
\item \textbf{Execution Environment}: Docker-based constraints provide approximations of real IoT conditions
\end{itemize}

Despite these limitations, the empirical results provide valuable insights for practical deployment decisions in IoT aggregation scenarios.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Discussion}
\label{chap:discussion}

\section{Alternative Privacy-Enhancing Technologies}

While our evaluation focuses on zk-SNARKs for verifiable IoT aggregation, several alternative privacy-enhancing technologies (PETs) offer different trade-offs in similar contexts. Understanding these alternatives helps position our contribution within the broader landscape of privacy-preserving IoT systems.

\subsection{Complementary PETs and Their Trade-offs}

\textbf{Differential Privacy} protects individuals by adding calibrated noise to aggregated results, but sacrifices utility and does not guarantee computational integrity \cite{dworkCalibratingNoiseSensitivity2006,dworkAlgorithmicFoundationsDifferential2013}. While effective for statistical privacy, differential privacy cannot provide the exact verification guarantees required for financial or regulatory compliance scenarios.

\textbf{Secure Multi-Party Computation (MPC)} allows computation over distributed inputs without a trusted third party, yet typically incurs high latency and communication overheads that are challenging for constrained IoT devices \cite{yaoHowGenerateExchange1986,goldreichHowPlayANY1987,damgardMultipartyComputationSomewhat2012}. The continuous communication requirements make MPC less suitable for the intermittent connectivity patterns common in IoT deployments.

\textbf{Trusted Execution Environments (TEEs)} provide hardware-backed isolation for secure computation, but introduce additional trust assumptions and are vulnerable to side-channel attacks. Furthermore, TEE availability varies significantly across IoT device classes, limiting deployment flexibility.

\textbf{ZK-STARKs} offer transparency and post-quantum security, but generally require larger proof sizes and higher prover costs compared to SNARK systems, making them less suitable for bandwidth-constrained IoT environments.

\subsection{Why zk-SNARKs for IoT Aggregation}

Given our goal of verifiable aggregation under device and bandwidth constraints, zk-SNARKs provide the optimal balance of proof succinctness, verification efficiency, and privacy guarantees. Our empirical evaluation demonstrates that recursive zk-SNARKs (Nova) can achieve constant-size verification while maintaining computational integrity, making them particularly suitable for resource-constrained IoT environments.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Conclusion \& Future Work}
\label{chap:conclusion}



\printbibliography

\end{document}


